{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5bd37a-4a9f-4dd7-8b43-45762f3547e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35866897-d8e0-464b-be89-1d0f90855681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del agente\n",
    "\n",
    "agent = PPG(state_dim = 11,\n",
    "            num_actions = 13,\n",
    "            actor_hidden_dim = 32,\n",
    "            critic_hidden_dim = 256,\n",
    "            epochs = 1,\n",
    "            epochs_aux = 6,\n",
    "            minibatch_size = 64,\n",
    "            lr = 0.0005,\n",
    "            lam = 0.95,\n",
    "            gamma = 0.99,\n",
    "            beta_s = .01,\n",
    "            eps_clip = 0.2,\n",
    "            value_clip = 0.4,\n",
    "            save_path = 'ppg_0')\n",
    "\n",
    "# Cargar modelo\n",
    "# agent.load('ppg_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fdecad8-b45b-47e8-9f1b-9b023ad2d9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Conectando con chrome...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 103.0.5060\n",
      "[WDM] - Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\danie\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Conexión establecida\n",
      "Episode 1/1000\n",
      "Steps = 100/100 | Mean Reward = -6.305 | Mean Iteration time = 2.744 s | Total Episode Time = 274.5s\n",
      "Episode 2/1000\n",
      "Steps = 100/100 | Mean Reward = -3.078 | Mean Iteration time = 2.742 s | Total Episode Time = 274.2s\n",
      "Episode 3/1000\n",
      "Steps = 100/100 | Mean Reward = -4.574 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 4/1000\n",
      "Steps = 100/100 | Mean Reward = -3.6 | Mean Iteration time = 2.727 s | Total Episode Time = 272.8s\n",
      "Episode 5/1000\n",
      "Steps = 100/100 | Mean Reward = -3.557 | Mean Iteration time = 2.723 s | Total Episode Time = 272.2s\n",
      "Episode 6/1000\n",
      "Steps = 100/100 | Mean Reward = -1.709 | Mean Iteration time = 2.83 s | Total Episode Time = 283.0s\n",
      "Episode 7/1000\n",
      "Steps = 100/100 | Mean Reward = -3.02 | Mean Iteration time = 2.725 s | Total Episode Time = 272.5s\n",
      "Episode 8/1000\n",
      "Steps = 100/100 | Mean Reward = -2.943 | Mean Iteration time = 2.686 s | Total Episode Time = 268.5s\n",
      "Episode 9/1000\n",
      "Steps = 100/100 | Mean Reward = -2.707 | Mean Iteration time = 2.748 s | Total Episode Time = 274.8s\n",
      "Episode 10/1000\n",
      "Steps = 100/100 | Mean Reward = -5.74 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 11/1000\n",
      "Steps = 100/100 | Mean Reward = -1.291 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 12/1000\n",
      "Steps = 100/100 | Mean Reward = -2.17 | Mean Iteration time = 2.76 s | Total Episode Time = 276.0s\n",
      "Episode 13/1000\n",
      "Steps = 100/100 | Mean Reward = -4.9 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 14/1000\n",
      "Steps = 100/100 | Mean Reward = -4.17 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 15/1000\n",
      "Steps = 100/100 | Mean Reward = -0.939 | Mean Iteration time = 2.742 s | Total Episode Time = 274.2s\n",
      "Episode 16/1000\n",
      "Steps = 100/100 | Mean Reward = -4.113 | Mean Iteration time = 2.91 s | Total Episode Time = 291.0s\n",
      "Episode 17/1000\n",
      "Steps = 100/100 | Mean Reward = -1.784 | Mean Iteration time = 2.727 s | Total Episode Time = 272.8s\n",
      "Episode 18/1000\n",
      "Steps = 100/100 | Mean Reward = 3.008 | Mean Iteration time = 2.814 s | Total Episode Time = 281.5s\n",
      "Episode 19/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6157 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 20/1000\n",
      "Steps = 100/100 | Mean Reward = -1.155 | Mean Iteration time = 2.678 s | Total Episode Time = 267.8s\n",
      "Episode 21/1000\n",
      "Steps = 100/100 | Mean Reward = 1.271 | Mean Iteration time = 2.756 s | Total Episode Time = 275.5s\n",
      "Episode 22/1000\n",
      "Steps = 100/100 | Mean Reward = -1.638 | Mean Iteration time = 2.55 s | Total Episode Time = 255.1s\n",
      "Episode 23/1000\n",
      "Steps = 100/100 | Mean Reward = -4.453 | Mean Iteration time = 2.52 s | Total Episode Time = 251.9s\n",
      "Episode 24/1000\n",
      "Steps = 100/100 | Mean Reward = -1.674 | Mean Iteration time = 2.574 s | Total Episode Time = 257.5s\n",
      "Episode 25/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7217 | Mean Iteration time = 2.477 s | Total Episode Time = 247.6s\n",
      "Episode 26/1000\n",
      "Steps = 100/100 | Mean Reward = -1.639 | Mean Iteration time = 204.4 s | Total Episode Time = 20430.0s\n",
      "Episode 27/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7476 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 28/1000\n",
      "Steps = 100/100 | Mean Reward = -1.628 | Mean Iteration time = 2.74 s | Total Episode Time = 274.0s\n",
      "Episode 29/1000\n",
      "Steps = 100/100 | Mean Reward = -3.59 | Mean Iteration time = 2.725 s | Total Episode Time = 272.5s\n",
      "Episode 30/1000\n",
      "Steps = 100/100 | Mean Reward = -4.477 | Mean Iteration time = 2.738 s | Total Episode Time = 273.8s\n",
      "Episode 31/1000\n",
      "Steps = 100/100 | Mean Reward = -3.2 | Mean Iteration time = 2.838 s | Total Episode Time = 283.8s\n",
      "Episode 32/1000\n",
      "Steps = 100/100 | Mean Reward = 0.7217 | Mean Iteration time = 2.69 s | Total Episode Time = 269.0s\n",
      "Episode 33/1000\n",
      "Steps = 100/100 | Mean Reward = -0.862 | Mean Iteration time = 2.777 s | Total Episode Time = 277.8s\n",
      "Episode 34/1000\n",
      "Steps = 100/100 | Mean Reward = -1.106 | Mean Iteration time = 2.8 s | Total Episode Time = 280.0s\n",
      "Episode 35/1000\n",
      "Steps = 100/100 | Mean Reward = -1.519 | Mean Iteration time = 2.717 s | Total Episode Time = 271.8s\n",
      "Episode 36/1000\n",
      "Steps = 100/100 | Mean Reward = -4.36 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 37/1000\n",
      "Steps = 100/100 | Mean Reward = -3.098 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 38/1000\n",
      "Steps = 100/100 | Mean Reward = -2.281 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 39/1000\n",
      "Steps = 100/100 | Mean Reward = -4.46 | Mean Iteration time = 2.762 s | Total Episode Time = 276.2s\n",
      "Episode 40/1000\n",
      "Steps = 100/100 | Mean Reward = -2.732 | Mean Iteration time = 2.73 s | Total Episode Time = 273.0s\n",
      "Episode 41/1000\n",
      "Steps = 100/100 | Mean Reward = -1.613 | Mean Iteration time = 2.88 s | Total Episode Time = 288.0s\n",
      "Episode 42/1000\n",
      "Steps = 100/100 | Mean Reward = -3.64 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 43/1000\n",
      "Steps = 100/100 | Mean Reward = -1.438 | Mean Iteration time = 2.783 s | Total Episode Time = 278.2s\n",
      "Episode 44/1000\n",
      "Steps = 100/100 | Mean Reward = -4.664 | Mean Iteration time = 2.752 s | Total Episode Time = 275.2s\n",
      "Episode 45/1000\n",
      "Steps = 100/100 | Mean Reward = -3.518 | Mean Iteration time = 2.723 s | Total Episode Time = 272.2s\n",
      "Episode 46/1000\n",
      "Steps = 100/100 | Mean Reward = -4.215 | Mean Iteration time = 2.768 s | Total Episode Time = 276.8s\n",
      "Episode 47/1000\n",
      "Steps = 100/100 | Mean Reward = -2.654 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 48/1000\n",
      "Steps = 100/100 | Mean Reward = -3.83 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 49/1000\n",
      "Steps = 100/100 | Mean Reward = -4.355 | Mean Iteration time = 2.686 s | Total Episode Time = 268.5s\n",
      "Episode 50/1000\n",
      "Steps = 100/100 | Mean Reward = -2.404 | Mean Iteration time = 2.79 s | Total Episode Time = 279.0s\n",
      "Episode 51/1000\n",
      "Steps = 100/100 | Mean Reward = -2.215 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 52/1000\n",
      "Steps = 100/100 | Mean Reward = -1.67 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 53/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3809 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 54/1000\n",
      "Steps = 100/100 | Mean Reward = -3.19 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 55/1000\n",
      "Steps = 100/100 | Mean Reward = -3.984 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 56/1000\n",
      "Steps = 100/100 | Mean Reward = -2.55 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 57/1000\n",
      "Steps = 100/100 | Mean Reward = -4.934 | Mean Iteration time = 2.678 s | Total Episode Time = 267.8s\n",
      "Episode 58/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4304 | Mean Iteration time = 2.783 s | Total Episode Time = 278.2s\n",
      "Episode 59/1000\n",
      "Steps = 100/100 | Mean Reward = -1.349 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 60/1000\n",
      "Steps = 100/100 | Mean Reward = -2.86 | Mean Iteration time = 2.766 s | Total Episode Time = 276.5s\n",
      "Episode 61/1000\n",
      "Steps = 100/100 | Mean Reward = -2.516 | Mean Iteration time = 2.852 s | Total Episode Time = 285.2s\n",
      "Episode 62/1000\n",
      "Steps = 100/100 | Mean Reward = 3.79 | Mean Iteration time = 2.875 s | Total Episode Time = 287.5s\n",
      "Episode 63/1000\n",
      "Steps = 100/100 | Mean Reward = -4.746 | Mean Iteration time = 2.744 s | Total Episode Time = 274.5s\n",
      "Episode 64/1000\n",
      "Steps = 100/100 | Mean Reward = -3.64 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 65/1000\n",
      "Steps = 100/100 | Mean Reward = -2.4 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 66/1000\n",
      "Steps = 100/100 | Mean Reward = -5.42 | Mean Iteration time = 2.613 s | Total Episode Time = 261.2s\n",
      "Episode 67/1000\n",
      "Steps = 100/100 | Mean Reward = -2.6 | Mean Iteration time = 2.58 s | Total Episode Time = 258.0s\n",
      "Episode 68/1000\n",
      "Steps = 100/100 | Mean Reward = -1.059 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 69/1000\n",
      "Steps = 100/100 | Mean Reward = -3.092 | Mean Iteration time = 2.564 s | Total Episode Time = 256.5s\n",
      "Episode 70/1000\n",
      "Steps = 100/100 | Mean Reward = 1.518 | Mean Iteration time = 2.668 s | Total Episode Time = 266.8s\n",
      "Episode 71/1000\n",
      "Steps = 100/100 | Mean Reward = -7.08 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 72/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7056 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 73/1000\n",
      "Steps = 100/100 | Mean Reward = -2.064 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 74/1000\n",
      "Steps = 100/100 | Mean Reward = -1.594 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 75/1000\n",
      "Steps = 100/100 | Mean Reward = -4.97 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 76/1000\n",
      "Steps = 100/100 | Mean Reward = -4.152 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 77/1000\n",
      "Steps = 100/100 | Mean Reward = -4.42 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 78/1000\n",
      "Steps = 100/100 | Mean Reward = -4.76 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 79/1000\n",
      "Steps = 100/100 | Mean Reward = -2.016 | Mean Iteration time = 2.574 s | Total Episode Time = 257.5s\n",
      "Episode 80/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8506 | Mean Iteration time = 2.625 s | Total Episode Time = 262.5s\n",
      "Episode 81/1000\n",
      "Steps = 100/100 | Mean Reward = -3.922 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 82/1000\n",
      "Steps = 100/100 | Mean Reward = 0.4055 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 83/1000\n",
      "Steps = 100/100 | Mean Reward = -3.17 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 84/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2998 | Mean Iteration time = 2.592 s | Total Episode Time = 259.2s\n",
      "Episode 85/1000\n",
      "Steps = 100/100 | Mean Reward = -3.244 | Mean Iteration time = 2.578 s | Total Episode Time = 257.8s\n",
      "Episode 86/1000\n",
      "Steps = 100/100 | Mean Reward = -5.344 | Mean Iteration time = 2.596 s | Total Episode Time = 259.5s\n",
      "Episode 87/1000\n",
      "Steps = 100/100 | Mean Reward = -5.164 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 88/1000\n",
      "Steps = 100/100 | Mean Reward = -5.81 | Mean Iteration time = 2.664 s | Total Episode Time = 266.5s\n",
      "Episode 89/1000\n",
      "Steps = 100/100 | Mean Reward = -1.855 | Mean Iteration time = 2.596 s | Total Episode Time = 259.5s\n",
      "Episode 90/1000\n",
      "Steps = 100/100 | Mean Reward = -1.74 | Mean Iteration time = 2.635 s | Total Episode Time = 263.5s\n",
      "Episode 91/1000\n",
      "Steps = 100/100 | Mean Reward = -1.753 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 92/1000\n",
      "Steps = 100/100 | Mean Reward = -2.186 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 93/1000\n",
      "Steps = 100/100 | Mean Reward = 2.676 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 94/1000\n",
      "Steps = 100/100 | Mean Reward = 1.893 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 95/1000\n",
      "Steps = 100/100 | Mean Reward = -4.33 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 96/1000\n",
      "Steps = 100/100 | Mean Reward = -3.47 | Mean Iteration time = 2.744 s | Total Episode Time = 274.5s\n",
      "Episode 97/1000\n",
      "Steps = 100/100 | Mean Reward = -2.71 | Mean Iteration time = 2.6 s | Total Episode Time = 260.0s\n",
      "Episode 98/1000\n",
      "Steps = 100/100 | Mean Reward = 4.125 | Mean Iteration time = 2.717 s | Total Episode Time = 271.8s\n",
      "Episode 99/1000\n",
      "Steps = 100/100 | Mean Reward = -4.844 | Mean Iteration time = 2.6 s | Total Episode Time = 260.0s\n",
      "Episode 100/1000\n",
      "Steps = 100/100 | Mean Reward = -6.82 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 101/1000\n",
      "Steps = 100/100 | Mean Reward = -2.984 | Mean Iteration time = 2.648 s | Total Episode Time = 264.8s\n",
      "Episode 102/1000\n",
      "Steps = 100/100 | Mean Reward = 0.683 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 103/1000\n",
      "Steps = 100/100 | Mean Reward = -1.852 | Mean Iteration time = 2.648 s | Total Episode Time = 264.8s\n",
      "Episode 104/1000\n",
      "Steps = 100/100 | Mean Reward = -2.342 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 105/1000\n",
      "Steps = 100/100 | Mean Reward = -3.885 | Mean Iteration time = 2.588 s | Total Episode Time = 258.8s\n",
      "Episode 106/1000\n",
      "Steps = 100/100 | Mean Reward = -2.555 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 107/1000\n",
      "Steps = 100/100 | Mean Reward = -3.805 | Mean Iteration time = 2.586 s | Total Episode Time = 258.5s\n",
      "Episode 108/1000\n",
      "Steps = 100/100 | Mean Reward = -5.504 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 109/1000\n",
      "Steps = 100/100 | Mean Reward = 1.289 | Mean Iteration time = 2.686 s | Total Episode Time = 268.5s\n",
      "Episode 110/1000\n",
      "Steps = 100/100 | Mean Reward = 3.855 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 111/1000\n",
      "Steps = 100/100 | Mean Reward = -5.363 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 112/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3413 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 113/1000\n",
      "Steps = 100/100 | Mean Reward = -2.57 | Mean Iteration time = 2.635 s | Total Episode Time = 263.5s\n",
      "Episode 114/1000\n",
      "Steps = 100/100 | Mean Reward = 1.46 | Mean Iteration time = 2.686 s | Total Episode Time = 268.5s\n",
      "Episode 115/1000\n",
      "Steps = 100/100 | Mean Reward = -2.432 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 116/1000\n",
      "Steps = 100/100 | Mean Reward = -3.596 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 117/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1653 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 118/1000\n",
      "Steps = 100/100 | Mean Reward = -1.771 | Mean Iteration time = 2.68 s | Total Episode Time = 268.0s\n",
      "Episode 119/1000\n",
      "Steps = 100/100 | Mean Reward = -1.952 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 120/1000\n",
      "Steps = 100/100 | Mean Reward = -2.402 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 121/1000\n",
      "Steps = 100/100 | Mean Reward = 1.072 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 122/1000\n",
      "Steps = 100/100 | Mean Reward = -3.926 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 123/1000\n",
      "Steps = 100/100 | Mean Reward = -6.55 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 124/1000\n",
      "Steps = 100/100 | Mean Reward = -4.242 | Mean Iteration time = 2.625 s | Total Episode Time = 262.5s\n",
      "Episode 125/1000\n",
      "Steps = 100/100 | Mean Reward = -2.74 | Mean Iteration time = 2.67 s | Total Episode Time = 267.0s\n",
      "Episode 126/1000\n",
      "Steps = 100/100 | Mean Reward = -6.246 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 127/1000\n",
      "Steps = 100/100 | Mean Reward = -0.1193 | Mean Iteration time = 2.752 s | Total Episode Time = 275.2s\n",
      "Episode 128/1000\n",
      "Steps = 100/100 | Mean Reward = -3.408 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 129/1000\n",
      "Steps = 100/100 | Mean Reward = -1.159 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 130/1000\n",
      "Steps = 100/100 | Mean Reward = -3.35 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 131/1000\n",
      "Steps = 100/100 | Mean Reward = -2.074 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 132/1000\n",
      "Steps = 100/100 | Mean Reward = -1.95 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 133/1000\n",
      "Steps = 100/100 | Mean Reward = -1.755 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 134/1000\n",
      "Steps = 100/100 | Mean Reward = -6.21 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 135/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6294 | Mean Iteration time = 2.705 s | Total Episode Time = 270.5s\n",
      "Episode 136/1000\n",
      "Steps = 100/100 | Mean Reward = -5.31 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 137/1000\n",
      "Steps = 100/100 | Mean Reward = -3.42 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 138/1000\n",
      "Steps = 100/100 | Mean Reward = -3.494 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 139/1000\n",
      "Steps = 100/100 | Mean Reward = -1.403 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 140/1000\n",
      "Steps = 100/100 | Mean Reward = -2.99 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 141/1000\n",
      "Steps = 100/100 | Mean Reward = -3.346 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 142/1000\n",
      "Steps = 100/100 | Mean Reward = -5.324 | Mean Iteration time = 2.787 s | Total Episode Time = 278.8s\n",
      "Episode 143/1000\n",
      "Steps = 100/100 | Mean Reward = -3.914 | Mean Iteration time = 2.738 s | Total Episode Time = 273.8s\n",
      "Episode 144/1000\n",
      "Steps = 100/100 | Mean Reward = -6.4 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 145/1000\n",
      "Steps = 100/100 | Mean Reward = -2.887 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 146/1000\n",
      "Steps = 100/100 | Mean Reward = -2.422 | Mean Iteration time = 2.574 s | Total Episode Time = 257.5s\n",
      "Episode 147/1000\n",
      "Steps = 100/100 | Mean Reward = -2.06 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 148/1000\n",
      "Steps = 100/100 | Mean Reward = -2.15 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 149/1000\n",
      "Steps = 100/100 | Mean Reward = -0.1709 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 150/1000\n",
      "Steps = 100/100 | Mean Reward = -1.249 | Mean Iteration time = 2.633 s | Total Episode Time = 263.2s\n",
      "Episode 151/1000\n",
      "Steps = 100/100 | Mean Reward = -4.86 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 152/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1882 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 153/1000\n",
      "Steps = 100/100 | Mean Reward = -3.072 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 154/1000\n",
      "Steps = 100/100 | Mean Reward = 3.266 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 155/1000\n",
      "Steps = 100/100 | Mean Reward = -2.182 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 156/1000\n",
      "Steps = 100/100 | Mean Reward = -0.5586 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 157/1000\n",
      "Steps = 100/100 | Mean Reward = -3.494 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 158/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2637 | Mean Iteration time = 2.717 s | Total Episode Time = 271.8s\n",
      "Episode 159/1000\n",
      "Steps = 100/100 | Mean Reward = 4.523 | Mean Iteration time = 2.838 s | Total Episode Time = 283.8s\n",
      "Episode 160/1000\n",
      "Steps = 100/100 | Mean Reward = -3.426 | Mean Iteration time = 2.68 s | Total Episode Time = 268.0s\n",
      "Episode 161/1000\n",
      "Steps = 100/100 | Mean Reward = -2.902 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 162/1000\n",
      "Steps = 100/100 | Mean Reward = -1.997 | Mean Iteration time = 2.793 s | Total Episode Time = 279.2s\n",
      "Episode 163/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7236 | Mean Iteration time = 2.73 s | Total Episode Time = 273.0s\n",
      "Episode 164/1000\n",
      "Steps = 100/100 | Mean Reward = -2.2 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 165/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2993 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 166/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1472 | Mean Iteration time = 2.635 s | Total Episode Time = 263.5s\n",
      "Episode 167/1000\n",
      "Steps = 100/100 | Mean Reward = -4.582 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 168/1000\n",
      "Steps = 100/100 | Mean Reward = -4.4 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 169/1000\n",
      "Steps = 100/100 | Mean Reward = -1.262 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 170/1000\n",
      "Steps = 100/100 | Mean Reward = -4.92 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 171/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8794 | Mean Iteration time = 2.648 s | Total Episode Time = 264.8s\n",
      "Episode 172/1000\n",
      "Steps = 100/100 | Mean Reward = -1.809 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 173/1000\n",
      "Steps = 100/100 | Mean Reward = -0.287 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 174/1000\n",
      "Steps = 100/100 | Mean Reward = -4.195 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 175/1000\n",
      "Steps = 100/100 | Mean Reward = -2.682 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 176/1000\n",
      "Steps = 100/100 | Mean Reward = -2.29 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 177/1000\n",
      "Steps = 100/100 | Mean Reward = -5.58 | Mean Iteration time = 2.6 s | Total Episode Time = 260.0s\n",
      "Episode 178/1000\n",
      "Steps = 100/100 | Mean Reward = -4.645 | Mean Iteration time = 2.633 s | Total Episode Time = 263.2s\n",
      "Episode 179/1000\n",
      "Steps = 100/100 | Mean Reward = 3.703 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 180/1000\n",
      "Steps = 100/100 | Mean Reward = -5.95 | Mean Iteration time = 2.613 s | Total Episode Time = 261.2s\n",
      "Episode 181/1000\n",
      "Steps = 100/100 | Mean Reward = -1.329 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 182/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2676 | Mean Iteration time = 2.613 s | Total Episode Time = 261.2s\n",
      "Episode 183/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1879 | Mean Iteration time = 2.676 s | Total Episode Time = 267.5s\n",
      "Episode 184/1000\n",
      "Steps = 100/100 | Mean Reward = -3.693 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 185/1000\n",
      "Steps = 100/100 | Mean Reward = 1.981 | Mean Iteration time = 2.633 s | Total Episode Time = 263.2s\n",
      "Episode 186/1000\n",
      "Steps = 100/100 | Mean Reward = -5.25 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 187/1000\n",
      "Steps = 100/100 | Mean Reward = -3.307 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 188/1000\n",
      "Steps = 100/100 | Mean Reward = 3.352 | Mean Iteration time = 2.78 s | Total Episode Time = 278.0s\n",
      "Episode 189/1000\n",
      "Steps = 100/100 | Mean Reward = -1.277 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 190/1000\n",
      "Steps = 100/100 | Mean Reward = 0.474 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 191/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3806 | Mean Iteration time = 2.664 s | Total Episode Time = 266.5s\n",
      "Episode 192/1000\n",
      "Steps = 100/100 | Mean Reward = -1.76 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 193/1000\n",
      "Steps = 100/100 | Mean Reward = -3.393 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 194/1000\n",
      "Steps = 100/100 | Mean Reward = -4.723 | Mean Iteration time = 2.625 s | Total Episode Time = 262.5s\n",
      "Episode 195/1000\n",
      "Steps = 100/100 | Mean Reward = -2.596 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 196/1000\n",
      "Steps = 100/100 | Mean Reward = -1.071 | Mean Iteration time = 2.635 s | Total Episode Time = 263.5s\n",
      "Episode 197/1000\n",
      "Steps = 100/100 | Mean Reward = -3.756 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 198/1000\n",
      "Steps = 100/100 | Mean Reward = -2.127 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 199/1000\n",
      "Steps = 100/100 | Mean Reward = -2.418 | Mean Iteration time = 2.783 s | Total Episode Time = 278.2s\n",
      "Episode 200/1000\n",
      "Steps = 100/100 | Mean Reward = -5.164 | Mean Iteration time = 2.57 s | Total Episode Time = 257.0s\n",
      "Episode 201/1000\n",
      "Steps = 100/100 | Mean Reward = -1.428 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 202/1000\n",
      "Steps = 100/100 | Mean Reward = -0.603 | Mean Iteration time = 2.664 s | Total Episode Time = 266.5s\n",
      "Episode 203/1000\n",
      "Steps = 100/100 | Mean Reward = -4.953 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 204/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3496 | Mean Iteration time = 2.648 s | Total Episode Time = 264.8s\n",
      "Episode 205/1000\n",
      "Steps = 100/100 | Mean Reward = -4.137 | Mean Iteration time = 2.625 s | Total Episode Time = 262.5s\n",
      "Episode 206/1000\n",
      "Steps = 100/100 | Mean Reward = -1.628 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 207/1000\n",
      "Steps = 100/100 | Mean Reward = -0.563 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 208/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6567 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 209/1000\n",
      "Steps = 100/100 | Mean Reward = 0.417 | Mean Iteration time = 2.812 s | Total Episode Time = 281.2s\n",
      "Episode 210/1000\n",
      "Steps = 100/100 | Mean Reward = -5.734 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 211/1000\n",
      "Steps = 100/100 | Mean Reward = -3.117 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 212/1000\n",
      "Steps = 100/100 | Mean Reward = -6.41 | Mean Iteration time = 2.586 s | Total Episode Time = 258.5s\n",
      "Episode 213/1000\n",
      "Steps = 100/100 | Mean Reward = 0.00967 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 214/1000\n",
      "Steps = 100/100 | Mean Reward = -5.81 | Mean Iteration time = 2.592 s | Total Episode Time = 259.2s\n",
      "Episode 215/1000\n",
      "Steps = 100/100 | Mean Reward = -1.926 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 216/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4194 | Mean Iteration time = 2.676 s | Total Episode Time = 267.5s\n",
      "Episode 217/1000\n",
      "Steps = 100/100 | Mean Reward = -2.715 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 218/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2009 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 219/1000\n",
      "Steps = 100/100 | Mean Reward = 1.253 | Mean Iteration time = 2.57 s | Total Episode Time = 257.0s\n",
      "Episode 220/1000\n",
      "Steps = 100/100 | Mean Reward = -3.064 | Mean Iteration time = 2.582 s | Total Episode Time = 258.2s\n",
      "Episode 221/1000\n",
      "Steps = 100/100 | Mean Reward = 0.455 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 222/1000\n",
      "Steps = 100/100 | Mean Reward = -1.704 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 223/1000\n",
      "Steps = 100/100 | Mean Reward = -1.683 | Mean Iteration time = 2.723 s | Total Episode Time = 272.2s\n",
      "Episode 224/1000\n",
      "Steps = 100/100 | Mean Reward = 0.008766 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 225/1000\n",
      "Steps = 100/100 | Mean Reward = -5.65 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 226/1000\n",
      "Steps = 100/100 | Mean Reward = 1.225 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 227/1000\n",
      "Steps = 100/100 | Mean Reward = -1.679 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 228/1000\n",
      "Steps = 100/100 | Mean Reward = -1.885 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 229/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8105 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 230/1000\n",
      "Steps = 100/100 | Mean Reward = -2.486 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 231/1000\n",
      "Steps = 100/100 | Mean Reward = 0.397 | Mean Iteration time = 2.77 s | Total Episode Time = 277.0s\n",
      "Episode 232/1000\n",
      "Steps = 100/100 | Mean Reward = -3.295 | Mean Iteration time = 2.625 s | Total Episode Time = 262.5s\n",
      "Episode 233/1000\n",
      "Steps = 100/100 | Mean Reward = -1.695 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 234/1000\n",
      "Steps = 100/100 | Mean Reward = -4.184 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 235/1000\n",
      "Steps = 100/100 | Mean Reward = -1.866 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 236/1000\n",
      "Steps = 100/100 | Mean Reward = -0.03183 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 237/1000\n",
      "Steps = 100/100 | Mean Reward = -5.24 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 238/1000\n",
      "Steps = 100/100 | Mean Reward = -1.874 | Mean Iteration time = 2.58 s | Total Episode Time = 258.0s\n",
      "Episode 239/1000\n",
      "Steps = 100/100 | Mean Reward = -6.79 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 240/1000\n",
      "Steps = 100/100 | Mean Reward = -5.38 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 241/1000\n",
      "Steps = 100/100 | Mean Reward = -1.643 | Mean Iteration time = 2.596 s | Total Episode Time = 259.5s\n",
      "Episode 242/1000\n",
      "Steps = 100/100 | Mean Reward = -1.227 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 243/1000\n",
      "Steps = 100/100 | Mean Reward = -2.664 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 244/1000\n",
      "Steps = 100/100 | Mean Reward = -1.55 | Mean Iteration time = 2.635 s | Total Episode Time = 263.5s\n",
      "Episode 245/1000\n",
      "Steps = 100/100 | Mean Reward = -1.487 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 246/1000\n",
      "Steps = 100/100 | Mean Reward = -2.12 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 247/1000\n",
      "Steps = 100/100 | Mean Reward = -4.1 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 248/1000\n",
      "Steps = 100/100 | Mean Reward = -2.451 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 249/1000\n",
      "Steps = 100/100 | Mean Reward = -1.25 | Mean Iteration time = 2.6 s | Total Episode Time = 260.0s\n",
      "Episode 250/1000\n",
      "Steps = 100/100 | Mean Reward = -0.0937 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 251/1000\n",
      "Steps = 100/100 | Mean Reward = -2.164 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 252/1000\n",
      "Steps = 100/100 | Mean Reward = -2.44 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 253/1000\n",
      "Steps = 100/100 | Mean Reward = -3.463 | Mean Iteration time = 2.57 s | Total Episode Time = 257.0s\n",
      "Episode 254/1000\n",
      "Steps = 100/100 | Mean Reward = -1.809 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 255/1000\n",
      "Steps = 100/100 | Mean Reward = -2.31 | Mean Iteration time = 2.596 s | Total Episode Time = 259.5s\n",
      "Episode 256/1000\n",
      "Steps = 100/100 | Mean Reward = -2.688 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 257/1000\n",
      "Steps = 100/100 | Mean Reward = -2.074 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 258/1000\n",
      "Steps = 100/100 | Mean Reward = -4.117 | Mean Iteration time = 2.586 s | Total Episode Time = 258.5s\n",
      "Episode 259/1000\n",
      "Steps = 100/100 | Mean Reward = 1.282 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 260/1000\n",
      "Steps = 100/100 | Mean Reward = -5.08 | Mean Iteration time = 2.578 s | Total Episode Time = 257.8s\n",
      "Episode 261/1000\n",
      "Steps = 100/100 | Mean Reward = -2.99 | Mean Iteration time = 2.613 s | Total Episode Time = 261.2s\n",
      "Episode 262/1000\n",
      "Steps = 100/100 | Mean Reward = 1.394 | Mean Iteration time = 2.592 s | Total Episode Time = 259.2s\n",
      "Episode 263/1000\n",
      "Steps = 100/100 | Mean Reward = -3.213 | Mean Iteration time = 2.574 s | Total Episode Time = 257.5s\n",
      "Episode 264/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2399 | Mean Iteration time = 2.73 s | Total Episode Time = 273.0s\n",
      "Episode 265/1000\n",
      "Steps = 100/100 | Mean Reward = -4.293 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 266/1000\n",
      "Steps = 100/100 | Mean Reward = -2.895 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 267/1000\n",
      "Steps = 100/100 | Mean Reward = -3.615 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 268/1000\n",
      "Steps = 100/100 | Mean Reward = -1.454 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 269/1000\n",
      "Steps = 100/100 | Mean Reward = -3.756 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 270/1000\n",
      "Steps = 100/100 | Mean Reward = 1.604 | Mean Iteration time = 2.893 s | Total Episode Time = 289.2s\n",
      "Episode 271/1000\n",
      "Steps = 100/100 | Mean Reward = 0.846 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 272/1000\n",
      "Steps = 100/100 | Mean Reward = -2.502 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 273/1000\n",
      "Steps = 100/100 | Mean Reward = 0.353 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 274/1000\n",
      "Steps = 100/100 | Mean Reward = -4.21 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 275/1000\n",
      "Steps = 100/100 | Mean Reward = -1.827 | Mean Iteration time = 2.582 s | Total Episode Time = 258.2s\n",
      "Episode 276/1000\n",
      "Steps = 100/100 | Mean Reward = -7.113 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 277/1000\n",
      "Steps = 100/100 | Mean Reward = -5.12 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 278/1000\n",
      "Steps = 100/100 | Mean Reward = -5.715 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 279/1000\n",
      "Steps = 100/100 | Mean Reward = -3.307 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 280/1000\n",
      "Steps = 100/100 | Mean Reward = -3.967 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 281/1000\n",
      "Steps = 100/100 | Mean Reward = -4.004 | Mean Iteration time = 2.625 s | Total Episode Time = 262.5s\n",
      "Episode 282/1000\n",
      "Steps = 100/100 | Mean Reward = -5.46 | Mean Iteration time = 2.592 s | Total Episode Time = 259.2s\n",
      "Episode 283/1000\n",
      "Steps = 100/100 | Mean Reward = -1.875 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 284/1000\n",
      "Steps = 100/100 | Mean Reward = -2.945 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 285/1000\n",
      "Steps = 100/100 | Mean Reward = -5.645 | Mean Iteration time = 2.625 s | Total Episode Time = 262.5s\n",
      "Episode 286/1000\n",
      "Steps = 100/100 | Mean Reward = -6.184 | Mean Iteration time = 2.596 s | Total Episode Time = 259.5s\n",
      "Episode 287/1000\n",
      "Steps = 100/100 | Mean Reward = -3.756 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 288/1000\n",
      "Steps = 100/100 | Mean Reward = -6.14 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 289/1000\n",
      "Steps = 100/100 | Mean Reward = -2.97 | Mean Iteration time = 2.592 s | Total Episode Time = 259.2s\n",
      "Episode 290/1000\n",
      "Steps = 100/100 | Mean Reward = -2.643 | Mean Iteration time = 2.67 s | Total Episode Time = 267.0s\n",
      "Episode 291/1000\n",
      "Steps = 100/100 | Mean Reward = -1.755 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 292/1000\n",
      "Steps = 100/100 | Mean Reward = -3.602 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 293/1000\n",
      "Steps = 100/100 | Mean Reward = -5.55 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 294/1000\n",
      "Steps = 100/100 | Mean Reward = -2.67 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 295/1000\n",
      "Steps = 100/100 | Mean Reward = -3.555 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 296/1000\n",
      "Steps = 100/100 | Mean Reward = -2.76 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 297/1000\n",
      "Steps = 100/100 | Mean Reward = -1.738 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 298/1000\n",
      "Steps = 100/100 | Mean Reward = -4.51 | Mean Iteration time = 2.742 s | Total Episode Time = 274.2s\n",
      "Episode 299/1000\n",
      "Steps = 100/100 | Mean Reward = -1.63 | Mean Iteration time = 2.705 s | Total Episode Time = 270.5s\n",
      "Episode 300/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4768 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 301/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2347 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 302/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2888 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 303/1000\n",
      "Steps = 100/100 | Mean Reward = -4.76 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 304/1000\n",
      "Steps = 100/100 | Mean Reward = -5.055 | Mean Iteration time = 2.57 s | Total Episode Time = 257.0s\n",
      "Episode 305/1000\n",
      "Steps = 100/100 | Mean Reward = -1.855 | Mean Iteration time = 2.668 s | Total Episode Time = 266.8s\n",
      "Episode 306/1000\n",
      "Steps = 100/100 | Mean Reward = -3.904 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 307/1000\n",
      "Steps = 100/100 | Mean Reward = 0.672 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 308/1000\n",
      "Steps = 100/100 | Mean Reward = -0.5073 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 309/1000\n",
      "Steps = 100/100 | Mean Reward = -3.695 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 310/1000\n",
      "Steps = 100/100 | Mean Reward = -5.246 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 311/1000\n",
      "Steps = 100/100 | Mean Reward = -1.968 | Mean Iteration time = 2.73 s | Total Episode Time = 273.0s\n",
      "Episode 312/1000\n",
      "Steps = 100/100 | Mean Reward = -5.5 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 313/1000\n",
      "Steps = 100/100 | Mean Reward = -0.459 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 314/1000\n",
      "Steps = 100/100 | Mean Reward = -2.365 | Mean Iteration time = 2.725 s | Total Episode Time = 272.5s\n",
      "Episode 315/1000\n",
      "Steps = 100/100 | Mean Reward = -6.113 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 316/1000\n",
      "Steps = 100/100 | Mean Reward = -1.203 | Mean Iteration time = 2.633 s | Total Episode Time = 263.2s\n",
      "Episode 317/1000\n",
      "Steps = 100/100 | Mean Reward = -2.586 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 318/1000\n",
      "Steps = 100/100 | Mean Reward = -4.84 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 319/1000\n",
      "Steps = 100/100 | Mean Reward = -1.934 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 320/1000\n",
      "Steps = 100/100 | Mean Reward = -3.805 | Mean Iteration time = 2.678 s | Total Episode Time = 267.8s\n",
      "Episode 321/1000\n",
      "Steps = 100/100 | Mean Reward = -1.468 | Mean Iteration time = 2.748 s | Total Episode Time = 274.8s\n",
      "Episode 322/1000\n",
      "Steps = 100/100 | Mean Reward = -3.8 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 323/1000\n",
      "Steps = 100/100 | Mean Reward = -5.36 | Mean Iteration time = 2.592 s | Total Episode Time = 259.2s\n",
      "Episode 324/1000\n",
      "Steps = 100/100 | Mean Reward = 0.9775 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 325/1000\n",
      "Steps = 100/100 | Mean Reward = -0.541 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 326/1000\n",
      "Steps = 100/100 | Mean Reward = -5.27 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 327/1000\n",
      "Steps = 100/100 | Mean Reward = -5.03 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 328/1000\n",
      "Steps = 100/100 | Mean Reward = 0.9067 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 329/1000\n",
      "Steps = 100/100 | Mean Reward = -1.8125 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 330/1000\n",
      "Steps = 100/100 | Mean Reward = -4.99 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 331/1000\n",
      "Steps = 100/100 | Mean Reward = -4.73 | Mean Iteration time = 2.588 s | Total Episode Time = 258.8s\n",
      "Episode 332/1000\n",
      "Steps = 100/100 | Mean Reward = -3.053 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 333/1000\n",
      "Steps = 100/100 | Mean Reward = -1.24 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 334/1000\n",
      "Steps = 100/100 | Mean Reward = 1.173 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 335/1000\n",
      "Steps = 100/100 | Mean Reward = 0.933 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 336/1000\n",
      "Steps = 100/100 | Mean Reward = 0.207 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 337/1000\n",
      "Steps = 100/100 | Mean Reward = -5.137 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 338/1000\n",
      "Steps = 100/100 | Mean Reward = -2.404 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 339/1000\n",
      "Steps = 100/100 | Mean Reward = 0.73 | Mean Iteration time = 2.664 s | Total Episode Time = 266.5s\n",
      "Episode 340/1000\n",
      "Steps = 100/100 | Mean Reward = -1.94 | Mean Iteration time = 2.588 s | Total Episode Time = 258.8s\n",
      "Episode 341/1000\n",
      "Steps = 100/100 | Mean Reward = -5.285 | Mean Iteration time = 2.648 s | Total Episode Time = 264.8s\n",
      "Episode 342/1000\n",
      "Steps = 100/100 | Mean Reward = -0.86 | Mean Iteration time = 2.734 s | Total Episode Time = 273.5s\n",
      "Episode 343/1000\n",
      "Steps = 100/100 | Mean Reward = 0.7827 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 344/1000\n",
      "Steps = 100/100 | Mean Reward = -5.22 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 345/1000\n",
      "Steps = 100/100 | Mean Reward = 0.288 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 346/1000\n",
      "Steps = 100/100 | Mean Reward = -4.42 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 347/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8413 | Mean Iteration time = 2.676 s | Total Episode Time = 267.5s\n",
      "Episode 348/1000\n",
      "Steps = 100/100 | Mean Reward = -1.339 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 349/1000\n",
      "Steps = 100/100 | Mean Reward = -4.023 | Mean Iteration time = 2.588 s | Total Episode Time = 258.8s\n",
      "Episode 350/1000\n",
      "Steps = 100/100 | Mean Reward = -0.5195 | Mean Iteration time = 2.633 s | Total Episode Time = 263.2s\n",
      "Episode 351/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3625 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 352/1000\n",
      "Steps = 100/100 | Mean Reward = -4.21 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 353/1000\n",
      "Steps = 100/100 | Mean Reward = -3.297 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 354/1000\n",
      "Steps = 100/100 | Mean Reward = -5.145 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 355/1000\n",
      "Steps = 100/100 | Mean Reward = -1.23 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 356/1000\n",
      "Steps = 100/100 | Mean Reward = -3.902 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 357/1000\n",
      "Steps = 100/100 | Mean Reward = -1.872 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 358/1000\n",
      "Steps = 100/100 | Mean Reward = -1.395 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 359/1000\n",
      "Steps = 100/100 | Mean Reward = -1.751 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 360/1000\n",
      "Steps = 100/100 | Mean Reward = -2.39 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 361/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1392 | Mean Iteration time = 2.67 s | Total Episode Time = 267.0s\n",
      "Episode 362/1000\n",
      "Steps = 100/100 | Mean Reward = -7.48 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 363/1000\n",
      "Steps = 100/100 | Mean Reward = -1.371 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 364/1000\n",
      "Steps = 100/100 | Mean Reward = -2.191 | Mean Iteration time = 2.74 s | Total Episode Time = 274.0s\n",
      "Episode 365/1000\n",
      "Steps = 100/100 | Mean Reward = -4.434 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 366/1000\n",
      "Steps = 100/100 | Mean Reward = -1.102 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 367/1000\n",
      "Steps = 100/100 | Mean Reward = -1.759 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 368/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4797 | Mean Iteration time = 2.727 s | Total Episode Time = 272.8s\n",
      "Episode 369/1000\n",
      "Steps = 100/100 | Mean Reward = -3.668 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 370/1000\n",
      "Steps = 100/100 | Mean Reward = -5.03 | Mean Iteration time = 2.582 s | Total Episode Time = 258.2s\n",
      "Episode 371/1000\n",
      "Steps = 100/100 | Mean Reward = -4.05 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 372/1000\n",
      "Steps = 100/100 | Mean Reward = -4.76 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 373/1000\n",
      "Steps = 100/100 | Mean Reward = -1.072 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 374/1000\n",
      "Steps = 100/100 | Mean Reward = -5.766 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 375/1000\n",
      "Steps = 100/100 | Mean Reward = -2.53 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 376/1000\n",
      "Steps = 100/100 | Mean Reward = -2.451 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 377/1000\n",
      "Steps = 100/100 | Mean Reward = -4.16 | Mean Iteration time = 2.68 s | Total Episode Time = 268.0s\n",
      "Episode 378/1000\n",
      "Steps = 100/100 | Mean Reward = -6.395 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 379/1000\n",
      "Steps = 100/100 | Mean Reward = -1.385 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 380/1000\n",
      "Steps = 100/100 | Mean Reward = -5.01 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 381/1000\n",
      "Steps = 100/100 | Mean Reward = -5.656 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 382/1000\n",
      "Steps = 100/100 | Mean Reward = 1.042 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 383/1000\n",
      "Steps = 100/100 | Mean Reward = -1.563 | Mean Iteration time = 2.732 s | Total Episode Time = 273.2s\n",
      "Episode 384/1000\n",
      "Steps = 100/100 | Mean Reward = -5.46 | Mean Iteration time = 2.648 s | Total Episode Time = 264.8s\n",
      "Episode 385/1000\n",
      "Steps = 100/100 | Mean Reward = -3.135 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 386/1000\n",
      "Steps = 100/100 | Mean Reward = 0.4624 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 387/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3928 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 388/1000\n",
      "Steps = 100/100 | Mean Reward = 0.03986 | Mean Iteration time = 2.785 s | Total Episode Time = 278.5s\n",
      "Episode 389/1000\n",
      "Steps = 100/100 | Mean Reward = -2.037 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 390/1000\n",
      "Steps = 100/100 | Mean Reward = -1.363 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 391/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2803 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 392/1000\n",
      "Steps = 100/100 | Mean Reward = -2.512 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 393/1000\n",
      "Steps = 100/100 | Mean Reward = -5.195 | Mean Iteration time = 2.633 s | Total Episode Time = 263.2s\n",
      "Episode 394/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7837 | Mean Iteration time = 2.648 s | Total Episode Time = 264.8s\n",
      "Episode 395/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1864 | Mean Iteration time = 2.723 s | Total Episode Time = 272.2s\n",
      "Episode 396/1000\n",
      "Steps = 100/100 | Mean Reward = -2.98 | Mean Iteration time = 2.633 s | Total Episode Time = 263.2s\n",
      "Episode 397/1000\n",
      "Steps = 100/100 | Mean Reward = -5.387 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 398/1000\n",
      "Steps = 100/100 | Mean Reward = -1.183 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 399/1000\n",
      "Steps = 100/100 | Mean Reward = -2.832 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 400/1000\n",
      "Steps = 100/100 | Mean Reward = -3.168 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 401/1000\n",
      "Steps = 100/100 | Mean Reward = -2.994 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 402/1000\n",
      "Steps = 100/100 | Mean Reward = 4.84 | Mean Iteration time = 2.824 s | Total Episode Time = 282.5s\n",
      "Episode 403/1000\n",
      "Steps = 100/100 | Mean Reward = 0.7495 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 404/1000\n",
      "Steps = 100/100 | Mean Reward = -1.375 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 405/1000\n",
      "Steps = 100/100 | Mean Reward = -5.363 | Mean Iteration time = 2.572 s | Total Episode Time = 257.2s\n",
      "Episode 406/1000\n",
      "Steps = 100/100 | Mean Reward = -1.282 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 407/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4038 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 408/1000\n",
      "Steps = 100/100 | Mean Reward = -3.586 | Mean Iteration time = 2.592 s | Total Episode Time = 259.2s\n",
      "Episode 409/1000\n",
      "Steps = 100/100 | Mean Reward = -0.0228 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 410/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2942 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 411/1000\n",
      "Steps = 100/100 | Mean Reward = -0.555 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 412/1000\n",
      "Steps = 100/100 | Mean Reward = -4.113 | Mean Iteration time = 2.678 s | Total Episode Time = 267.8s\n",
      "Episode 413/1000\n",
      "Steps = 100/100 | Mean Reward = 2.387 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 414/1000\n",
      "Steps = 100/100 | Mean Reward = -2.105 | Mean Iteration time = 2.625 s | Total Episode Time = 262.5s\n",
      "Episode 415/1000\n",
      "Steps = 100/100 | Mean Reward = -3.773 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 416/1000\n",
      "Steps = 100/100 | Mean Reward = -3.277 | Mean Iteration time = 2.705 s | Total Episode Time = 270.5s\n",
      "Episode 417/1000\n",
      "Steps = 100/100 | Mean Reward = -1.4 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 418/1000\n",
      "Steps = 100/100 | Mean Reward = -1.826 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 419/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3032 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 420/1000\n",
      "Steps = 100/100 | Mean Reward = -4.344 | Mean Iteration time = 2.588 s | Total Episode Time = 258.8s\n",
      "Episode 421/1000\n",
      "Steps = 100/100 | Mean Reward = 0.623 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 422/1000\n",
      "Steps = 100/100 | Mean Reward = -1.834 | Mean Iteration time = 2.744 s | Total Episode Time = 274.5s\n",
      "Episode 423/1000\n",
      "Steps = 100/100 | Mean Reward = -1.566 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 424/1000\n",
      "Steps = 100/100 | Mean Reward = -2.818 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 425/1000\n",
      "Steps = 100/100 | Mean Reward = -2.748 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 426/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4453 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 427/1000\n",
      "Steps = 100/100 | Mean Reward = -2.574 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 428/1000\n",
      "Steps = 100/100 | Mean Reward = -0.0331 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 429/1000\n",
      "Steps = 100/100 | Mean Reward = -2.596 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 430/1000\n",
      "Steps = 100/100 | Mean Reward = -3.848 | Mean Iteration time = 2.613 s | Total Episode Time = 261.2s\n",
      "Episode 431/1000\n",
      "Steps = 100/100 | Mean Reward = -1.347 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 432/1000\n",
      "Steps = 100/100 | Mean Reward = -3.006 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 433/1000\n",
      "Steps = 100/100 | Mean Reward = -2.975 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 434/1000\n",
      "Steps = 100/100 | Mean Reward = -2.562 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 435/1000\n",
      "Steps = 100/100 | Mean Reward = -1.184 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 436/1000\n",
      "Steps = 100/100 | Mean Reward = -0.5996 | Mean Iteration time = 2.572 s | Total Episode Time = 257.2s\n",
      "Episode 437/1000\n",
      "Steps = 100/100 | Mean Reward = -4.836 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 438/1000\n",
      "Steps = 100/100 | Mean Reward = -1.711 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 439/1000\n",
      "Steps = 100/100 | Mean Reward = -5.6 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 440/1000\n",
      "Steps = 100/100 | Mean Reward = -4.367 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 441/1000\n",
      "Steps = 100/100 | Mean Reward = 5.6 | Mean Iteration time = 2.865 s | Total Episode Time = 286.5s\n",
      "Episode 442/1000\n",
      "Steps = 100/100 | Mean Reward = -1.977 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 443/1000\n",
      "Steps = 100/100 | Mean Reward = -2.318 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 444/1000\n",
      "Steps = 100/100 | Mean Reward = -1.565 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 445/1000\n",
      "Steps = 100/100 | Mean Reward = 4.016 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 446/1000\n",
      "Steps = 100/100 | Mean Reward = -2.37 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 447/1000\n",
      "Steps = 100/100 | Mean Reward = -4.168 | Mean Iteration time = 2.564 s | Total Episode Time = 256.5s\n",
      "Episode 448/1000\n",
      "Steps = 100/100 | Mean Reward = 1.24 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 449/1000\n",
      "Steps = 100/100 | Mean Reward = 1.254 | Mean Iteration time = 2.756 s | Total Episode Time = 275.5s\n",
      "Episode 450/1000\n",
      "Steps = 100/100 | Mean Reward = -4.68 | Mean Iteration time = 2.67 s | Total Episode Time = 267.0s\n",
      "Episode 451/1000\n",
      "Steps = 100/100 | Mean Reward = 0.4216 | Mean Iteration time = 2.6 s | Total Episode Time = 260.0s\n",
      "Episode 452/1000\n",
      "Steps = 100/100 | Mean Reward = -4.73 | Mean Iteration time = 2.61 s | Total Episode Time = 261.0s\n",
      "Episode 453/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3682 | Mean Iteration time = 2.875 s | Total Episode Time = 287.5s\n",
      "Episode 454/1000\n",
      "Steps = 100/100 | Mean Reward = -0.91 | Mean Iteration time = 2.824 s | Total Episode Time = 282.5s\n",
      "Episode 455/1000\n",
      "Steps = 100/100 | Mean Reward = -4.684 | Mean Iteration time = 3.13 s | Total Episode Time = 313.0s\n",
      "Episode 456/1000\n",
      "Steps = 100/100 | Mean Reward = 2.797 | Mean Iteration time = 2.258 s | Total Episode Time = 225.9s\n",
      "Episode 457/1000\n",
      "Steps = 100/100 | Mean Reward = -2.36 | Mean Iteration time = 2.787 s | Total Episode Time = 278.8s\n",
      "Episode 458/1000\n",
      "Steps = 100/100 | Mean Reward = -5.31 | Mean Iteration time = 2.838 s | Total Episode Time = 283.8s\n",
      "Episode 459/1000\n",
      "Steps = 100/100 | Mean Reward = -2.898 | Mean Iteration time = 2.748 s | Total Episode Time = 274.8s\n",
      "Episode 460/1000\n",
      "Steps = 100/100 | Mean Reward = -3.08 | Mean Iteration time = 2.875 s | Total Episode Time = 287.5s\n",
      "Episode 461/1000\n",
      "Steps = 100/100 | Mean Reward = 2.28 | Mean Iteration time = 2.305 s | Total Episode Time = 230.4s\n",
      "Episode 462/1000\n",
      "Steps = 100/100 | Mean Reward = -1.651 | Mean Iteration time = 2.938 s | Total Episode Time = 293.8s\n",
      "Episode 463/1000\n",
      "Steps = 100/100 | Mean Reward = 1.375 | Mean Iteration time = 3.34 s | Total Episode Time = 334.0s\n",
      "Episode 464/1000\n",
      "Steps = 100/100 | Mean Reward = 0.2358 | Mean Iteration time = 2.94 s | Total Episode Time = 294.0s\n",
      "Episode 465/1000\n",
      "Steps = 100/100 | Mean Reward = -2.12 | Mean Iteration time = 3.912 s | Total Episode Time = 391.2s\n",
      "Episode 466/1000\n",
      "Steps = 100/100 | Mean Reward = -1.466 | Mean Iteration time = 3.885 s | Total Episode Time = 388.5s\n",
      "Episode 467/1000\n",
      "Steps = 100/100 | Mean Reward = -6.67 | Mean Iteration time = 5.48 s | Total Episode Time = 548.0s\n",
      "Episode 468/1000\n",
      "Steps = 100/100 | Mean Reward = -5.074 | Mean Iteration time = 4.87 s | Total Episode Time = 487.0s\n",
      "Episode 469/1000\n",
      "Steps = 100/100 | Mean Reward = -6.29 | Mean Iteration time = 4.816 s | Total Episode Time = 481.8s\n",
      "Episode 470/1000\n",
      "Steps = 100/100 | Mean Reward = -3.625 | Mean Iteration time = 5.67 s | Total Episode Time = 567.0s\n",
      "Episode 471/1000\n",
      "Steps = 100/100 | Mean Reward = -1.523 | Mean Iteration time = 5.44 s | Total Episode Time = 544.0s\n",
      "Episode 472/1000\n",
      "Steps = 100/100 | Mean Reward = -5.14 | Mean Iteration time = 4.45 s | Total Episode Time = 445.0s\n",
      "Episode 473/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.463 s | Total Episode Time = 246.4s\n",
      "Episode 474/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.453 s | Total Episode Time = 245.4s\n",
      "Episode 475/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.498 s | Total Episode Time = 249.9s\n",
      "Episode 476/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.328 s | Total Episode Time = 232.8s\n",
      "Episode 477/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.486 s | Total Episode Time = 248.6s\n",
      "Episode 478/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.432 s | Total Episode Time = 243.2s\n",
      "Episode 479/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.477 s | Total Episode Time = 247.6s\n",
      "Episode 480/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.4 s | Total Episode Time = 240.1s\n",
      "Episode 481/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.436 s | Total Episode Time = 243.6s\n",
      "Episode 482/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.498 s | Total Episode Time = 249.8s\n",
      "Episode 483/1000\n",
      "Steps = 100/100 | Mean Reward = -8.29 | Mean Iteration time = 2.357 s | Total Episode Time = 235.8s\n",
      "Episode 484/1000\n",
      "Steps = 100/100 | Mean Reward = -5.824 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 485/1000\n",
      "Steps = 100/100 | Mean Reward = -4.004 | Mean Iteration time = 5.996 s | Total Episode Time = 599.5s\n",
      "Episode 486/1000\n",
      "Steps = 100/100 | Mean Reward = -5.32 | Mean Iteration time = 4.742 s | Total Episode Time = 474.2s\n",
      "Episode 487/1000\n",
      "Steps = 100/100 | Mean Reward = -4.36 | Mean Iteration time = 5.64 s | Total Episode Time = 564.0s\n",
      "Episode 488/1000\n",
      "Steps = 100/100 | Mean Reward = -7.055 | Mean Iteration time = 5.246 s | Total Episode Time = 524.5s\n",
      "Episode 489/1000\n",
      "Steps = 100/100 | Mean Reward = -1.105 | Mean Iteration time = 4.74 s | Total Episode Time = 473.8s\n",
      "Episode 490/1000\n",
      "Steps = 100/100 | Mean Reward = -3.908 | Mean Iteration time = 3.03 s | Total Episode Time = 303.0s\n",
      "Episode 491/1000\n",
      "Steps = 100/100 | Mean Reward = -1.152 | Mean Iteration time = 2.783 s | Total Episode Time = 278.2s\n",
      "Episode 492/1000\n",
      "Steps = 100/100 | Mean Reward = 4.56 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 493/1000\n",
      "Steps = 100/100 | Mean Reward = 1.604 | Mean Iteration time = 2.21 s | Total Episode Time = 221.0s\n",
      "Episode 494/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1746 | Mean Iteration time = 2.908 s | Total Episode Time = 290.8s\n",
      "Episode 495/1000\n",
      "Steps = 100/100 | Mean Reward = -1.722 | Mean Iteration time = 2.875 s | Total Episode Time = 287.5s\n",
      "Episode 496/1000\n",
      "Steps = 100/100 | Mean Reward = 0.05872 | Mean Iteration time = 2.992 s | Total Episode Time = 299.2s\n",
      "Episode 497/1000\n",
      "Steps = 100/100 | Mean Reward = -17.08 | Mean Iteration time = 2.0 s | Total Episode Time = 200.0s\n",
      "Episode 498/1000\n",
      "Steps = 100/100 | Mean Reward = -17.08 | Mean Iteration time = 1.997 s | Total Episode Time = 199.8s\n",
      "Episode 499/1000\n",
      "Steps = 100/100 | Mean Reward = -17.08 | Mean Iteration time = 1.991 s | Total Episode Time = 199.1s\n",
      "Episode 500/1000\n",
      "Steps = 100/100 | Mean Reward = -17.08 | Mean Iteration time = 2.002 s | Total Episode Time = 200.1s\n",
      "Episode 501/1000\n",
      "Steps = 100/100 | Mean Reward = -17.08 | Mean Iteration time = 1.996 s | Total Episode Time = 199.6s\n",
      "Episode 502/1000\n",
      "Steps = 100/100 | Mean Reward = -17.08 | Mean Iteration time = 1.994 s | Total Episode Time = 199.4s\n",
      "Episode 503/1000\n",
      "Steps = 100/100 | Mean Reward = -17.08 | Mean Iteration time = 2.002 s | Total Episode Time = 200.1s\n",
      "Episode 504/1000\n",
      "Steps = 100/100 | Mean Reward = -11.08 | Mean Iteration time = 2.23 s | Total Episode Time = 223.1s\n",
      "Episode 505/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6733 | Mean Iteration time = 2.805 s | Total Episode Time = 280.5s\n",
      "Episode 506/1000\n",
      "Steps = 100/100 | Mean Reward = -4.86 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 507/1000\n",
      "Steps = 100/100 | Mean Reward = -3.006 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 508/1000\n",
      "Steps = 100/100 | Mean Reward = -6.953 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 509/1000\n",
      "Steps = 100/100 | Mean Reward = -4.08 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 510/1000\n",
      "Steps = 100/100 | Mean Reward = -3.893 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 511/1000\n",
      "Steps = 100/100 | Mean Reward = -2.176 | Mean Iteration time = 2.836 s | Total Episode Time = 283.5s\n",
      "Episode 512/1000\n",
      "Steps = 100/100 | Mean Reward = -4.168 | Mean Iteration time = 2.686 s | Total Episode Time = 268.5s\n",
      "Episode 513/1000\n",
      "Steps = 100/100 | Mean Reward = 0.5337 | Mean Iteration time = 2.68 s | Total Episode Time = 268.0s\n",
      "Episode 514/1000\n",
      "Steps = 100/100 | Mean Reward = -3.068 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 515/1000\n",
      "Steps = 100/100 | Mean Reward = -3.568 | Mean Iteration time = 2.664 s | Total Episode Time = 266.5s\n",
      "Episode 516/1000\n",
      "Steps = 100/100 | Mean Reward = -0.814 | Mean Iteration time = 2.705 s | Total Episode Time = 270.5s\n",
      "Episode 517/1000\n",
      "Steps = 100/100 | Mean Reward = -3.305 | Mean Iteration time = 2.67 s | Total Episode Time = 267.0s\n",
      "Episode 518/1000\n",
      "Steps = 100/100 | Mean Reward = 1.129 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 519/1000\n",
      "Steps = 100/100 | Mean Reward = 3.836 | Mean Iteration time = 2.855 s | Total Episode Time = 285.5s\n",
      "Episode 520/1000\n",
      "Steps = 100/100 | Mean Reward = -1.544 | Mean Iteration time = 2.68 s | Total Episode Time = 268.0s\n",
      "Episode 521/1000\n",
      "Steps = 100/100 | Mean Reward = -6.63 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 522/1000\n",
      "Steps = 100/100 | Mean Reward = -1.765 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 523/1000\n",
      "Steps = 100/100 | Mean Reward = -1.034 | Mean Iteration time = 2.78 s | Total Episode Time = 278.0s\n",
      "Episode 524/1000\n",
      "Steps = 100/100 | Mean Reward = -2.84 | Mean Iteration time = 2.75 s | Total Episode Time = 275.0s\n",
      "Episode 525/1000\n",
      "Steps = 100/100 | Mean Reward = 1.193 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 526/1000\n",
      "Steps = 100/100 | Mean Reward = 1.334 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 527/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3948 | Mean Iteration time = 2.8 s | Total Episode Time = 280.0s\n",
      "Episode 528/1000\n",
      "Steps = 100/100 | Mean Reward = -2.396 | Mean Iteration time = 2.74 s | Total Episode Time = 274.0s\n",
      "Episode 529/1000\n",
      "Steps = 100/100 | Mean Reward = -3.098 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 530/1000\n",
      "Steps = 100/100 | Mean Reward = -3.885 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 531/1000\n",
      "Steps = 100/100 | Mean Reward = 0.333 | Mean Iteration time = 2.732 s | Total Episode Time = 273.2s\n",
      "Episode 532/1000\n",
      "Steps = 100/100 | Mean Reward = -1.512 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 533/1000\n",
      "Steps = 100/100 | Mean Reward = -1.858 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 534/1000\n",
      "Steps = 100/100 | Mean Reward = -5.04 | Mean Iteration time = 2.613 s | Total Episode Time = 261.2s\n",
      "Episode 535/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8223 | Mean Iteration time = 2.812 s | Total Episode Time = 281.2s\n",
      "Episode 536/1000\n",
      "Steps = 100/100 | Mean Reward = 1.762 | Mean Iteration time = 2.865 s | Total Episode Time = 286.5s\n",
      "Episode 537/1000\n",
      "Steps = 100/100 | Mean Reward = -5.22 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 538/1000\n",
      "Steps = 100/100 | Mean Reward = 2.148 | Mean Iteration time = 2.807 s | Total Episode Time = 280.8s\n",
      "Episode 539/1000\n",
      "Steps = 100/100 | Mean Reward = -3.922 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 540/1000\n",
      "Steps = 100/100 | Mean Reward = 1.423 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 541/1000\n",
      "Steps = 100/100 | Mean Reward = -2.037 | Mean Iteration time = 2.725 s | Total Episode Time = 272.5s\n",
      "Episode 542/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3284 | Mean Iteration time = 2.752 s | Total Episode Time = 275.2s\n",
      "Episode 543/1000\n",
      "Steps = 100/100 | Mean Reward = -2.64 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 544/1000\n",
      "Steps = 100/100 | Mean Reward = -2.824 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 545/1000\n",
      "Steps = 100/100 | Mean Reward = -3.46 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 546/1000\n",
      "Steps = 100/100 | Mean Reward = -3.482 | Mean Iteration time = 2.738 s | Total Episode Time = 273.8s\n",
      "Episode 547/1000\n",
      "Steps = 100/100 | Mean Reward = -2.963 | Mean Iteration time = 2.67 s | Total Episode Time = 267.0s\n",
      "Episode 548/1000\n",
      "Steps = 100/100 | Mean Reward = -4.816 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 549/1000\n",
      "Steps = 100/100 | Mean Reward = -0.9844 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 550/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1233 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 551/1000\n",
      "Steps = 100/100 | Mean Reward = -1.696 | Mean Iteration time = 2.67 s | Total Episode Time = 267.0s\n",
      "Episode 552/1000\n",
      "Steps = 100/100 | Mean Reward = -1.956 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 553/1000\n",
      "Steps = 100/100 | Mean Reward = -2.205 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 554/1000\n",
      "Steps = 100/100 | Mean Reward = -1.51 | Mean Iteration time = 2.822 s | Total Episode Time = 282.2s\n",
      "Episode 555/1000\n",
      "Steps = 100/100 | Mean Reward = -1.857 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 556/1000\n",
      "Steps = 100/100 | Mean Reward = -2.89 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 557/1000\n",
      "Steps = 100/100 | Mean Reward = -2.668 | Mean Iteration time = 2.68 s | Total Episode Time = 268.0s\n",
      "Episode 558/1000\n",
      "Steps = 100/100 | Mean Reward = 0.2952 | Mean Iteration time = 2.664 s | Total Episode Time = 266.5s\n",
      "Episode 559/1000\n",
      "Steps = 100/100 | Mean Reward = -1.668 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 560/1000\n",
      "Steps = 100/100 | Mean Reward = -1.579 | Mean Iteration time = 2.648 s | Total Episode Time = 264.8s\n",
      "Episode 561/1000\n",
      "Steps = 100/100 | Mean Reward = -5.113 | Mean Iteration time = 2.686 s | Total Episode Time = 268.5s\n",
      "Episode 562/1000\n",
      "Steps = 100/100 | Mean Reward = -0.9126 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 563/1000\n",
      "Steps = 100/100 | Mean Reward = -2.34 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 564/1000\n",
      "Steps = 100/100 | Mean Reward = -7.13 | Mean Iteration time = 2.617 s | Total Episode Time = 261.8s\n",
      "Episode 565/1000\n",
      "Steps = 100/100 | Mean Reward = -1.447 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 566/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3076 | Mean Iteration time = 2.752 s | Total Episode Time = 275.2s\n",
      "Episode 567/1000\n",
      "Steps = 100/100 | Mean Reward = -1.215 | Mean Iteration time = 2.676 s | Total Episode Time = 267.5s\n",
      "Episode 568/1000\n",
      "Steps = 100/100 | Mean Reward = 1.675 | Mean Iteration time = 2.78 s | Total Episode Time = 278.0s\n",
      "Episode 569/1000\n",
      "Steps = 100/100 | Mean Reward = -2.758 | Mean Iteration time = 2.756 s | Total Episode Time = 275.5s\n",
      "Episode 570/1000\n",
      "Steps = 100/100 | Mean Reward = -1.631 | Mean Iteration time = 2.734 s | Total Episode Time = 273.5s\n",
      "Episode 571/1000\n",
      "Steps = 100/100 | Mean Reward = -5.695 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 572/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6187 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 573/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1377 | Mean Iteration time = 2.703 s | Total Episode Time = 270.2s\n",
      "Episode 574/1000\n",
      "Steps = 100/100 | Mean Reward = -2.36 | Mean Iteration time = 2.73 s | Total Episode Time = 273.0s\n",
      "Episode 575/1000\n",
      "Steps = 100/100 | Mean Reward = -3.03 | Mean Iteration time = 2.69 s | Total Episode Time = 269.0s\n",
      "Episode 576/1000\n",
      "Steps = 100/100 | Mean Reward = -5.344 | Mean Iteration time = 2.69 s | Total Episode Time = 269.0s\n",
      "Episode 577/1000\n",
      "Steps = 100/100 | Mean Reward = -2.617 | Mean Iteration time = 2.62 s | Total Episode Time = 262.0s\n",
      "Episode 578/1000\n",
      "Steps = 100/100 | Mean Reward = -4.234 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 579/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4644 | Mean Iteration time = 2.69 s | Total Episode Time = 269.0s\n",
      "Episode 580/1000\n",
      "Steps = 100/100 | Mean Reward = -1.486 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 581/1000\n",
      "Steps = 100/100 | Mean Reward = -1.624 | Mean Iteration time = 2.766 s | Total Episode Time = 276.5s\n",
      "Episode 582/1000\n",
      "Steps = 100/100 | Mean Reward = 0.2047 | Mean Iteration time = 2.664 s | Total Episode Time = 266.5s\n",
      "Episode 583/1000\n",
      "Steps = 100/100 | Mean Reward = -0.57 | Mean Iteration time = 2.686 s | Total Episode Time = 268.5s\n",
      "Episode 584/1000\n",
      "Steps = 100/100 | Mean Reward = -0.748 | Mean Iteration time = 2.68 s | Total Episode Time = 268.0s\n",
      "Episode 585/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3706 | Mean Iteration time = 2.69 s | Total Episode Time = 269.0s\n",
      "Episode 586/1000\n",
      "Steps = 100/100 | Mean Reward = -2.51 | Mean Iteration time = 2.69 s | Total Episode Time = 269.0s\n",
      "Episode 587/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4617 | Mean Iteration time = 2.98 s | Total Episode Time = 298.0s\n",
      "Episode 588/1000\n",
      "Steps = 100/100 | Mean Reward = -3.557 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 589/1000\n",
      "Steps = 100/100 | Mean Reward = -4.1 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 590/1000\n",
      "Steps = 100/100 | Mean Reward = -5.395 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 591/1000\n",
      "Steps = 100/100 | Mean Reward = -1.258 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 592/1000\n",
      "Steps = 100/100 | Mean Reward = -1.41 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 593/1000\n",
      "Steps = 100/100 | Mean Reward = -1.028 | Mean Iteration time = 2.727 s | Total Episode Time = 272.8s\n",
      "Episode 594/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3638 | Mean Iteration time = 3.01 s | Total Episode Time = 301.0s\n",
      "Episode 595/1000\n",
      "Steps = 100/100 | Mean Reward = -4.17 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 596/1000\n",
      "Steps = 100/100 | Mean Reward = -2.518 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 597/1000\n",
      "Steps = 100/100 | Mean Reward = -3.373 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 598/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3582 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 599/1000\n",
      "Steps = 100/100 | Mean Reward = -2.271 | Mean Iteration time = 2.664 s | Total Episode Time = 266.5s\n",
      "Episode 600/1000\n",
      "Steps = 100/100 | Mean Reward = -1.135 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 601/1000\n",
      "Steps = 100/100 | Mean Reward = -1.983 | Mean Iteration time = 2.768 s | Total Episode Time = 276.8s\n",
      "Episode 602/1000\n",
      "Steps = 100/100 | Mean Reward = -4.89 | Mean Iteration time = 2.63 s | Total Episode Time = 263.0s\n",
      "Episode 603/1000\n",
      "Steps = 100/100 | Mean Reward = 0.668 | Mean Iteration time = 2.705 s | Total Episode Time = 270.5s\n",
      "Episode 604/1000\n",
      "Steps = 100/100 | Mean Reward = 1.593 | Mean Iteration time = 2.793 s | Total Episode Time = 279.2s\n",
      "Episode 605/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7686 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 606/1000\n",
      "Steps = 100/100 | Mean Reward = -1.808 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 607/1000\n",
      "Steps = 100/100 | Mean Reward = 0.478 | Mean Iteration time = 2.855 s | Total Episode Time = 285.5s\n",
      "Episode 608/1000\n",
      "Steps = 100/100 | Mean Reward = -3.78 | Mean Iteration time = 2.678 s | Total Episode Time = 267.8s\n",
      "Episode 609/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2108 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 610/1000\n",
      "Steps = 100/100 | Mean Reward = -2.11 | Mean Iteration time = 2.68 s | Total Episode Time = 268.0s\n",
      "Episode 611/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2576 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 612/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3162 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 613/1000\n",
      "Steps = 100/100 | Mean Reward = -2.963 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 614/1000\n",
      "Steps = 100/100 | Mean Reward = -3.992 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 615/1000\n",
      "Steps = 100/100 | Mean Reward = -3.574 | Mean Iteration time = 2.678 s | Total Episode Time = 267.8s\n",
      "Episode 616/1000\n",
      "Steps = 100/100 | Mean Reward = 3.13 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 617/1000\n",
      "Steps = 100/100 | Mean Reward = 0.4854 | Mean Iteration time = 2.668 s | Total Episode Time = 266.8s\n",
      "Episode 618/1000\n",
      "Steps = 100/100 | Mean Reward = -2.549 | Mean Iteration time = 2.773 s | Total Episode Time = 277.2s\n",
      "Episode 619/1000\n",
      "Steps = 100/100 | Mean Reward = -1.209 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 620/1000\n",
      "Steps = 100/100 | Mean Reward = -2.6 | Mean Iteration time = 2.777 s | Total Episode Time = 277.8s\n",
      "Episode 621/1000\n",
      "Steps = 100/100 | Mean Reward = -3.945 | Mean Iteration time = 2.67 s | Total Episode Time = 267.0s\n",
      "Episode 622/1000\n",
      "Steps = 100/100 | Mean Reward = 0.7417 | Mean Iteration time = 2.75 s | Total Episode Time = 275.0s\n",
      "Episode 623/1000\n",
      "Steps = 100/100 | Mean Reward = -6.914 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 624/1000\n",
      "Steps = 100/100 | Mean Reward = -2.123 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 625/1000\n",
      "Steps = 100/100 | Mean Reward = 0.03784 | Mean Iteration time = 2.797 s | Total Episode Time = 279.8s\n",
      "Episode 626/1000\n",
      "Steps = 100/100 | Mean Reward = -2.523 | Mean Iteration time = 2.678 s | Total Episode Time = 267.8s\n",
      "Episode 627/1000\n",
      "Steps = 100/100 | Mean Reward = -1.478 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 628/1000\n",
      "Steps = 100/100 | Mean Reward = -1.354 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 629/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1065 | Mean Iteration time = 2.822 s | Total Episode Time = 282.2s\n",
      "Episode 630/1000\n",
      "Steps = 100/100 | Mean Reward = -2.021 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 631/1000\n",
      "Steps = 100/100 | Mean Reward = -1.271 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 632/1000\n",
      "Steps = 100/100 | Mean Reward = -0.509 | Mean Iteration time = 2.777 s | Total Episode Time = 277.8s\n",
      "Episode 633/1000\n",
      "Steps = 100/100 | Mean Reward = -3.395 | Mean Iteration time = 2.678 s | Total Episode Time = 267.8s\n",
      "Episode 634/1000\n",
      "Steps = 100/100 | Mean Reward = 0.101 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 635/1000\n",
      "Steps = 100/100 | Mean Reward = -2.271 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 636/1000\n",
      "Steps = 100/100 | Mean Reward = -0.709 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 637/1000\n",
      "Steps = 100/100 | Mean Reward = -1.433 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 638/1000\n",
      "Steps = 100/100 | Mean Reward = -1.756 | Mean Iteration time = 2.768 s | Total Episode Time = 276.8s\n",
      "Episode 639/1000\n",
      "Steps = 100/100 | Mean Reward = -2.717 | Mean Iteration time = 3.027 s | Total Episode Time = 302.8s\n",
      "Episode 640/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6577 | Mean Iteration time = 3.193 s | Total Episode Time = 319.2s\n",
      "Episode 641/1000\n",
      "Steps = 100/100 | Mean Reward = -4.99 | Mean Iteration time = 3.152 s | Total Episode Time = 315.2s\n",
      "Episode 642/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3955 | Mean Iteration time = 3.117 s | Total Episode Time = 311.8s\n",
      "Episode 643/1000\n",
      "Steps = 100/100 | Mean Reward = -0.478 | Mean Iteration time = 3.188 s | Total Episode Time = 318.8s\n",
      "Episode 644/1000\n",
      "Steps = 100/100 | Mean Reward = -2.945 | Mean Iteration time = 2.785 s | Total Episode Time = 278.5s\n",
      "Episode 645/1000\n",
      "Steps = 100/100 | Mean Reward = -3.3 | Mean Iteration time = 2.797 s | Total Episode Time = 279.8s\n",
      "Episode 646/1000\n",
      "Steps = 100/100 | Mean Reward = -0.03763 | Mean Iteration time = 2.795 s | Total Episode Time = 279.5s\n",
      "Episode 647/1000\n",
      "Steps = 100/100 | Mean Reward = -1.928 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 648/1000\n",
      "Steps = 100/100 | Mean Reward = 6.445 | Mean Iteration time = 2.11 s | Total Episode Time = 211.0s\n",
      "Episode 649/1000\n",
      "Steps = 100/100 | Mean Reward = 6.39 | Mean Iteration time = 1.968 s | Total Episode Time = 196.8s\n",
      "Episode 650/1000\n",
      "Steps = 100/100 | Mean Reward = 6.39 | Mean Iteration time = 1.979 s | Total Episode Time = 197.9s\n",
      "Episode 651/1000\n",
      "Steps = 100/100 | Mean Reward = 6.39 | Mean Iteration time = 1.98 s | Total Episode Time = 198.0s\n",
      "Episode 652/1000\n",
      "Steps = 100/100 | Mean Reward = 6.39 | Mean Iteration time = 1.966 s | Total Episode Time = 196.6s\n",
      "Episode 653/1000\n",
      "Steps = 100/100 | Mean Reward = 6.39 | Mean Iteration time = 1.98 s | Total Episode Time = 198.0s\n",
      "Episode 654/1000\n",
      "Steps = 100/100 | Mean Reward = 4.926 | Mean Iteration time = 2.283 s | Total Episode Time = 228.4s\n",
      "Episode 655/1000\n",
      "Steps = 100/100 | Mean Reward = 0.2494 | Mean Iteration time = 2.78 s | Total Episode Time = 278.0s\n",
      "Episode 656/1000\n",
      "Steps = 100/100 | Mean Reward = -4.04 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 657/1000\n",
      "Steps = 100/100 | Mean Reward = -1.818 | Mean Iteration time = 2.805 s | Total Episode Time = 280.5s\n",
      "Episode 658/1000\n",
      "Steps = 100/100 | Mean Reward = 1.389 | Mean Iteration time = 2.756 s | Total Episode Time = 275.5s\n",
      "Episode 659/1000\n",
      "Steps = 100/100 | Mean Reward = -4.297 | Mean Iteration time = 2.805 s | Total Episode Time = 280.5s\n",
      "Episode 660/1000\n",
      "Steps = 100/100 | Mean Reward = -0.915 | Mean Iteration time = 2.814 s | Total Episode Time = 281.5s\n",
      "Episode 661/1000\n",
      "Steps = 100/100 | Mean Reward = -3.457 | Mean Iteration time = 2.865 s | Total Episode Time = 286.5s\n",
      "Episode 662/1000\n",
      "Steps = 100/100 | Mean Reward = -0.006386 | Mean Iteration time = 2.75 s | Total Episode Time = 275.0s\n",
      "Episode 663/1000\n",
      "Steps = 100/100 | Mean Reward = -2.264 | Mean Iteration time = 2.87 s | Total Episode Time = 287.0s\n",
      "Episode 664/1000\n",
      "Steps = 100/100 | Mean Reward = -1.947 | Mean Iteration time = 2.734 s | Total Episode Time = 273.5s\n",
      "Episode 665/1000\n",
      "Steps = 100/100 | Mean Reward = -4.13 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 666/1000\n",
      "Steps = 100/100 | Mean Reward = -0.01252 | Mean Iteration time = 2.795 s | Total Episode Time = 279.5s\n",
      "Episode 667/1000\n",
      "Steps = 100/100 | Mean Reward = -3.02 | Mean Iteration time = 2.795 s | Total Episode Time = 279.5s\n",
      "Episode 668/1000\n",
      "Steps = 100/100 | Mean Reward = -6.066 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 669/1000\n",
      "Steps = 100/100 | Mean Reward = -1.863 | Mean Iteration time = 2.78 s | Total Episode Time = 278.0s\n",
      "Episode 670/1000\n",
      "Steps = 100/100 | Mean Reward = 0.05606 | Mean Iteration time = 2.838 s | Total Episode Time = 283.8s\n",
      "Episode 671/1000\n",
      "Steps = 100/100 | Mean Reward = 0.524 | Mean Iteration time = 2.732 s | Total Episode Time = 273.2s\n",
      "Episode 672/1000\n",
      "Steps = 100/100 | Mean Reward = -3.873 | Mean Iteration time = 2.762 s | Total Episode Time = 276.2s\n",
      "Episode 673/1000\n",
      "Steps = 100/100 | Mean Reward = -0.994 | Mean Iteration time = 2.732 s | Total Episode Time = 273.2s\n",
      "Episode 674/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2347 | Mean Iteration time = 2.984 s | Total Episode Time = 298.5s\n",
      "Episode 675/1000\n",
      "Steps = 100/100 | Mean Reward = -2.72 | Mean Iteration time = 2.93 s | Total Episode Time = 293.0s\n",
      "Episode 676/1000\n",
      "Steps = 100/100 | Mean Reward = -0.9023 | Mean Iteration time = 2.88 s | Total Episode Time = 288.0s\n",
      "Episode 677/1000\n",
      "Steps = 100/100 | Mean Reward = -9.16 | Mean Iteration time = 3.455 s | Total Episode Time = 345.5s\n",
      "Episode 678/1000\n",
      "Steps = 100/100 | Mean Reward = -1.372 | Mean Iteration time = 3.305 s | Total Episode Time = 330.5s\n",
      "Episode 679/1000\n",
      "Steps = 100/100 | Mean Reward = -4.44 | Mean Iteration time = 3.54 s | Total Episode Time = 354.0s\n",
      "Episode 680/1000\n",
      "Steps = 100/100 | Mean Reward = -0.1368 | Mean Iteration time = 3.742 s | Total Episode Time = 374.2s\n",
      "Episode 681/1000\n",
      "Steps = 100/100 | Mean Reward = 0.0645 | Mean Iteration time = 3.512 s | Total Episode Time = 351.2s\n",
      "Episode 682/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8813 | Mean Iteration time = 3.338 s | Total Episode Time = 333.8s\n",
      "Episode 683/1000\n",
      "Steps = 100/100 | Mean Reward = -1.994 | Mean Iteration time = 2.81 s | Total Episode Time = 281.0s\n",
      "Episode 684/1000\n",
      "Steps = 100/100 | Mean Reward = -1.57 | Mean Iteration time = 2.787 s | Total Episode Time = 278.8s\n",
      "Episode 685/1000\n",
      "Steps = 100/100 | Mean Reward = -5.23 | Mean Iteration time = 2.777 s | Total Episode Time = 277.8s\n",
      "Episode 686/1000\n",
      "Steps = 100/100 | Mean Reward = -4.434 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 687/1000\n",
      "Steps = 100/100 | Mean Reward = -2.533 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 688/1000\n",
      "Steps = 100/100 | Mean Reward = -2.936 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 689/1000\n",
      "Steps = 100/100 | Mean Reward = -5.92 | Mean Iteration time = 2.762 s | Total Episode Time = 276.2s\n",
      "Episode 690/1000\n",
      "Steps = 100/100 | Mean Reward = -2.744 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 691/1000\n",
      "Steps = 100/100 | Mean Reward = -3.195 | Mean Iteration time = 2.814 s | Total Episode Time = 281.5s\n",
      "Episode 692/1000\n",
      "Steps = 100/100 | Mean Reward = -2.83 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 693/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1614 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 694/1000\n",
      "Steps = 100/100 | Mean Reward = -2.41 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 695/1000\n",
      "Steps = 100/100 | Mean Reward = -3.635 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 696/1000\n",
      "Steps = 100/100 | Mean Reward = 1.324 | Mean Iteration time = 2.77 s | Total Episode Time = 277.0s\n",
      "Episode 697/1000\n",
      "Steps = 100/100 | Mean Reward = -2.19 | Mean Iteration time = 2.81 s | Total Episode Time = 281.0s\n",
      "Episode 698/1000\n",
      "Steps = 100/100 | Mean Reward = -1.595 | Mean Iteration time = 2.773 s | Total Episode Time = 277.2s\n",
      "Episode 699/1000\n",
      "Steps = 100/100 | Mean Reward = -0.519 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 700/1000\n",
      "Steps = 100/100 | Mean Reward = -4.887 | Mean Iteration time = 2.66 s | Total Episode Time = 266.0s\n",
      "Episode 701/1000\n",
      "Steps = 100/100 | Mean Reward = 1.501 | Mean Iteration time = 2.775 s | Total Episode Time = 277.5s\n",
      "Episode 702/1000\n",
      "Steps = 100/100 | Mean Reward = 0.873 | Mean Iteration time = 2.865 s | Total Episode Time = 286.5s\n",
      "Episode 703/1000\n",
      "Steps = 100/100 | Mean Reward = -2.324 | Mean Iteration time = 2.77 s | Total Episode Time = 277.0s\n",
      "Episode 704/1000\n",
      "Steps = 100/100 | Mean Reward = -0.9995 | Mean Iteration time = 2.654 s | Total Episode Time = 265.5s\n",
      "Episode 705/1000\n",
      "Steps = 100/100 | Mean Reward = -4.945 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 706/1000\n",
      "Steps = 100/100 | Mean Reward = -0.36 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 707/1000\n",
      "Steps = 100/100 | Mean Reward = -5.07 | Mean Iteration time = 2.73 s | Total Episode Time = 273.0s\n",
      "Episode 708/1000\n",
      "Steps = 100/100 | Mean Reward = -3.195 | Mean Iteration time = 2.76 s | Total Episode Time = 276.0s\n",
      "Episode 709/1000\n",
      "Steps = 100/100 | Mean Reward = -3.205 | Mean Iteration time = 2.762 s | Total Episode Time = 276.2s\n",
      "Episode 710/1000\n",
      "Steps = 100/100 | Mean Reward = 0.8125 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 711/1000\n",
      "Steps = 100/100 | Mean Reward = -3.867 | Mean Iteration time = 2.725 s | Total Episode Time = 272.5s\n",
      "Episode 712/1000\n",
      "Steps = 100/100 | Mean Reward = -2.342 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 713/1000\n",
      "Steps = 100/100 | Mean Reward = -4.48 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 714/1000\n",
      "Steps = 100/100 | Mean Reward = -3.377 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 715/1000\n",
      "Steps = 100/100 | Mean Reward = -6.64 | Mean Iteration time = 2.936 s | Total Episode Time = 293.5s\n",
      "Episode 716/1000\n",
      "Steps = 100/100 | Mean Reward = -9.516 | Mean Iteration time = 2.742 s | Total Episode Time = 274.2s\n",
      "Episode 717/1000\n",
      "Steps = 100/100 | Mean Reward = -3.188 | Mean Iteration time = 3.01 s | Total Episode Time = 301.0s\n",
      "Episode 718/1000\n",
      "Steps = 100/100 | Mean Reward = -0.561 | Mean Iteration time = 2.922 s | Total Episode Time = 292.2s\n",
      "Episode 719/1000\n",
      "Steps = 100/100 | Mean Reward = 0.2332 | Mean Iteration time = 2.82 s | Total Episode Time = 282.0s\n",
      "Episode 720/1000\n",
      "Steps = 100/100 | Mean Reward = -2.408 | Mean Iteration time = 2.818 s | Total Episode Time = 281.8s\n",
      "Episode 721/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3574 | Mean Iteration time = 2.88 s | Total Episode Time = 288.0s\n",
      "Episode 722/1000\n",
      "Steps = 100/100 | Mean Reward = -1.315 | Mean Iteration time = 2.928 s | Total Episode Time = 292.8s\n",
      "Episode 723/1000\n",
      "Steps = 100/100 | Mean Reward = -4.496 | Mean Iteration time = 2.885 s | Total Episode Time = 288.5s\n",
      "Episode 724/1000\n",
      "Steps = 100/100 | Mean Reward = -3.645 | Mean Iteration time = 2.893 s | Total Episode Time = 289.2s\n",
      "Episode 725/1000\n",
      "Steps = 100/100 | Mean Reward = -3.84 | Mean Iteration time = 2.883 s | Total Episode Time = 288.2s\n",
      "Episode 726/1000\n",
      "Steps = 100/100 | Mean Reward = -0.752 | Mean Iteration time = 2.98 s | Total Episode Time = 298.0s\n",
      "Episode 727/1000\n",
      "Steps = 100/100 | Mean Reward = -4.785 | Mean Iteration time = 2.86 s | Total Episode Time = 286.0s\n",
      "Episode 728/1000\n",
      "Steps = 100/100 | Mean Reward = 0.276 | Mean Iteration time = 3.002 s | Total Episode Time = 300.2s\n",
      "Episode 729/1000\n",
      "Steps = 100/100 | Mean Reward = -0.0674 | Mean Iteration time = 3.117 s | Total Episode Time = 311.8s\n",
      "Episode 730/1000\n",
      "Steps = 100/100 | Mean Reward = -3.21 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 731/1000\n",
      "Steps = 100/100 | Mean Reward = -0.363 | Mean Iteration time = 2.76 s | Total Episode Time = 276.0s\n",
      "Episode 732/1000\n",
      "Steps = 100/100 | Mean Reward = -2.342 | Mean Iteration time = 2.873 s | Total Episode Time = 287.2s\n",
      "Episode 733/1000\n",
      "Steps = 100/100 | Mean Reward = -4.758 | Mean Iteration time = 2.928 s | Total Episode Time = 292.8s\n",
      "Episode 734/1000\n",
      "Steps = 100/100 | Mean Reward = -3.0 | Mean Iteration time = 2.773 s | Total Episode Time = 277.2s\n",
      "Episode 735/1000\n",
      "Steps = 100/100 | Mean Reward = -4.83 | Mean Iteration time = 2.773 s | Total Episode Time = 277.2s\n",
      "Episode 736/1000\n",
      "Steps = 100/100 | Mean Reward = -5.844 | Mean Iteration time = 2.818 s | Total Episode Time = 281.8s\n",
      "Episode 737/1000\n",
      "Steps = 100/100 | Mean Reward = -2.686 | Mean Iteration time = 2.8 s | Total Episode Time = 280.0s\n",
      "Episode 738/1000\n",
      "Steps = 100/100 | Mean Reward = -1.113 | Mean Iteration time = 2.775 s | Total Episode Time = 277.5s\n",
      "Episode 739/1000\n",
      "Steps = 100/100 | Mean Reward = -3.346 | Mean Iteration time = 2.904 s | Total Episode Time = 290.5s\n",
      "Episode 740/1000\n",
      "Steps = 100/100 | Mean Reward = 1.237 | Mean Iteration time = 3.062 s | Total Episode Time = 306.2s\n",
      "Episode 741/1000\n",
      "Steps = 100/100 | Mean Reward = -3.322 | Mean Iteration time = 2.814 s | Total Episode Time = 281.5s\n",
      "Episode 742/1000\n",
      "Steps = 100/100 | Mean Reward = -3.797 | Mean Iteration time = 2.867 s | Total Episode Time = 286.8s\n",
      "Episode 743/1000\n",
      "Steps = 100/100 | Mean Reward = -3.775 | Mean Iteration time = 2.848 s | Total Episode Time = 284.8s\n",
      "Episode 744/1000\n",
      "Steps = 100/100 | Mean Reward = -5.42 | Mean Iteration time = 2.98 s | Total Episode Time = 298.0s\n",
      "Episode 745/1000\n",
      "Steps = 100/100 | Mean Reward = -6.13 | Mean Iteration time = 2.766 s | Total Episode Time = 276.5s\n",
      "Episode 746/1000\n",
      "Steps = 100/100 | Mean Reward = -2.37 | Mean Iteration time = 2.838 s | Total Episode Time = 283.8s\n",
      "Episode 747/1000\n",
      "Steps = 100/100 | Mean Reward = -4.316 | Mean Iteration time = 2.863 s | Total Episode Time = 286.2s\n",
      "Episode 748/1000\n",
      "Steps = 100/100 | Mean Reward = -1.29 | Mean Iteration time = 2.988 s | Total Episode Time = 298.8s\n",
      "Episode 749/1000\n",
      "Steps = 100/100 | Mean Reward = -7.215 | Mean Iteration time = 2.842 s | Total Episode Time = 284.2s\n",
      "Episode 750/1000\n",
      "Steps = 100/100 | Mean Reward = -6.92 | Mean Iteration time = 2.785 s | Total Episode Time = 278.5s\n",
      "Episode 751/1000\n",
      "Steps = 100/100 | Mean Reward = -2.434 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 752/1000\n",
      "Steps = 100/100 | Mean Reward = -3.688 | Mean Iteration time = 2.588 s | Total Episode Time = 258.8s\n",
      "Episode 753/1000\n",
      "Steps = 100/100 | Mean Reward = -6.363 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 754/1000\n",
      "Steps = 100/100 | Mean Reward = -2.176 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 755/1000\n",
      "Steps = 100/100 | Mean Reward = -2.697 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 756/1000\n",
      "Steps = 100/100 | Mean Reward = -5.094 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 757/1000\n",
      "Steps = 100/100 | Mean Reward = -4.977 | Mean Iteration time = 2.56 s | Total Episode Time = 256.0s\n",
      "Episode 758/1000\n",
      "Steps = 100/100 | Mean Reward = -4.414 | Mean Iteration time = 2.572 s | Total Episode Time = 257.2s\n",
      "Episode 759/1000\n",
      "Steps = 100/100 | Mean Reward = -4.3 | Mean Iteration time = 2.613 s | Total Episode Time = 261.2s\n",
      "Episode 760/1000\n",
      "Steps = 100/100 | Mean Reward = -4.17 | Mean Iteration time = 2.562 s | Total Episode Time = 256.2s\n",
      "Episode 761/1000\n",
      "Steps = 100/100 | Mean Reward = -4.867 | Mean Iteration time = 2.582 s | Total Episode Time = 258.2s\n",
      "Episode 762/1000\n",
      "Steps = 100/100 | Mean Reward = 0.1669 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 763/1000\n",
      "Steps = 100/100 | Mean Reward = -2.04 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 764/1000\n",
      "Steps = 100/100 | Mean Reward = -4.51 | Mean Iteration time = 2.545 s | Total Episode Time = 254.5s\n",
      "Episode 765/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7627 | Mean Iteration time = 2.545 s | Total Episode Time = 254.5s\n",
      "Episode 766/1000\n",
      "Steps = 100/100 | Mean Reward = -1.481 | Mean Iteration time = 2.557 s | Total Episode Time = 255.6s\n",
      "Episode 767/1000\n",
      "Steps = 100/100 | Mean Reward = -0.086 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 768/1000\n",
      "Steps = 100/100 | Mean Reward = -3.893 | Mean Iteration time = 2.55 s | Total Episode Time = 255.1s\n",
      "Episode 769/1000\n",
      "Steps = 100/100 | Mean Reward = -2.738 | Mean Iteration time = 2.549 s | Total Episode Time = 254.9s\n",
      "Episode 770/1000\n",
      "Steps = 100/100 | Mean Reward = -0.908 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 771/1000\n",
      "Steps = 100/100 | Mean Reward = -5.035 | Mean Iteration time = 2.537 s | Total Episode Time = 253.8s\n",
      "Episode 772/1000\n",
      "Steps = 100/100 | Mean Reward = -1.735 | Mean Iteration time = 2.543 s | Total Episode Time = 254.4s\n",
      "Episode 773/1000\n",
      "Steps = 100/100 | Mean Reward = -3.223 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 774/1000\n",
      "Steps = 100/100 | Mean Reward = -2.676 | Mean Iteration time = 2.557 s | Total Episode Time = 255.6s\n",
      "Episode 775/1000\n",
      "Steps = 100/100 | Mean Reward = -4.2 | Mean Iteration time = 2.557 s | Total Episode Time = 255.8s\n",
      "Episode 776/1000\n",
      "Steps = 100/100 | Mean Reward = -2.918 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 777/1000\n",
      "Steps = 100/100 | Mean Reward = -4.496 | Mean Iteration time = 2.602 s | Total Episode Time = 260.2s\n",
      "Episode 778/1000\n",
      "Steps = 100/100 | Mean Reward = -2.238 | Mean Iteration time = 2.516 s | Total Episode Time = 251.5s\n",
      "Episode 779/1000\n",
      "Steps = 100/100 | Mean Reward = -1.687 | Mean Iteration time = 2.572 s | Total Episode Time = 257.2s\n",
      "Episode 780/1000\n",
      "Steps = 100/100 | Mean Reward = -2.717 | Mean Iteration time = 2.523 s | Total Episode Time = 252.2s\n",
      "Episode 781/1000\n",
      "Steps = 100/100 | Mean Reward = -3.463 | Mean Iteration time = 2.545 s | Total Episode Time = 254.5s\n",
      "Episode 782/1000\n",
      "Steps = 100/100 | Mean Reward = -0.459 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 783/1000\n",
      "Steps = 100/100 | Mean Reward = -2.154 | Mean Iteration time = 2.562 s | Total Episode Time = 256.2s\n",
      "Episode 784/1000\n",
      "Steps = 100/100 | Mean Reward = 0.001792 | Mean Iteration time = 2.525 s | Total Episode Time = 252.5s\n",
      "Episode 785/1000\n",
      "Steps = 100/100 | Mean Reward = -3.605 | Mean Iteration time = 2.54 s | Total Episode Time = 253.9s\n",
      "Episode 786/1000\n",
      "Steps = 100/100 | Mean Reward = -2.83 | Mean Iteration time = 2.547 s | Total Episode Time = 254.6s\n",
      "Episode 787/1000\n",
      "Steps = 100/100 | Mean Reward = -0.717 | Mean Iteration time = 2.568 s | Total Episode Time = 256.8s\n",
      "Episode 788/1000\n",
      "Steps = 100/100 | Mean Reward = -0.9927 | Mean Iteration time = 2.56 s | Total Episode Time = 256.0s\n",
      "Episode 789/1000\n",
      "Steps = 100/100 | Mean Reward = -0.10455 | Mean Iteration time = 2.807 s | Total Episode Time = 280.8s\n",
      "Episode 790/1000\n",
      "Steps = 100/100 | Mean Reward = -0.378 | Mean Iteration time = 2.53 s | Total Episode Time = 253.0s\n",
      "Episode 791/1000\n",
      "Steps = 100/100 | Mean Reward = 0.929 | Mean Iteration time = 2.53 s | Total Episode Time = 253.0s\n",
      "Episode 792/1000\n",
      "Steps = 100/100 | Mean Reward = 1.203 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 793/1000\n",
      "Steps = 100/100 | Mean Reward = -3.908 | Mean Iteration time = 2.56 s | Total Episode Time = 256.0s\n",
      "Episode 794/1000\n",
      "Steps = 100/100 | Mean Reward = -3.398 | Mean Iteration time = 2.506 s | Total Episode Time = 250.6s\n",
      "Episode 795/1000\n",
      "Steps = 100/100 | Mean Reward = -3.697 | Mean Iteration time = 2.59 s | Total Episode Time = 259.0s\n",
      "Episode 796/1000\n",
      "Steps = 100/100 | Mean Reward = -3.48 | Mean Iteration time = 2.56 s | Total Episode Time = 256.0s\n",
      "Episode 797/1000\n",
      "Steps = 100/100 | Mean Reward = -5.055 | Mean Iteration time = 2.596 s | Total Episode Time = 259.5s\n",
      "Episode 798/1000\n",
      "Steps = 100/100 | Mean Reward = -5.785 | Mean Iteration time = 2.537 s | Total Episode Time = 253.6s\n",
      "Episode 799/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2827 | Mean Iteration time = 2.703 s | Total Episode Time = 270.2s\n",
      "Episode 800/1000\n",
      "Steps = 100/100 | Mean Reward = -3.68 | Mean Iteration time = 2.545 s | Total Episode Time = 254.5s\n",
      "Episode 801/1000\n",
      "Steps = 100/100 | Mean Reward = -1.589 | Mean Iteration time = 2.53 s | Total Episode Time = 253.0s\n",
      "Episode 802/1000\n",
      "Steps = 100/100 | Mean Reward = -1.602 | Mean Iteration time = 2.543 s | Total Episode Time = 254.4s\n",
      "Episode 803/1000\n",
      "Steps = 100/100 | Mean Reward = -2.441 | Mean Iteration time = 2.623 s | Total Episode Time = 262.2s\n",
      "Episode 804/1000\n",
      "Steps = 100/100 | Mean Reward = -3.686 | Mean Iteration time = 2.592 s | Total Episode Time = 259.2s\n",
      "Episode 805/1000\n",
      "Steps = 100/100 | Mean Reward = -3.988 | Mean Iteration time = 2.557 s | Total Episode Time = 255.6s\n",
      "Episode 806/1000\n",
      "Steps = 100/100 | Mean Reward = -5.03 | Mean Iteration time = 2.541 s | Total Episode Time = 254.1s\n",
      "Episode 807/1000\n",
      "Steps = 100/100 | Mean Reward = -1.568 | Mean Iteration time = 2.605 s | Total Episode Time = 260.5s\n",
      "Episode 808/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2223 | Mean Iteration time = 2.572 s | Total Episode Time = 257.2s\n",
      "Episode 809/1000\n",
      "Steps = 100/100 | Mean Reward = 2.74 | Mean Iteration time = 2.553 s | Total Episode Time = 255.2s\n",
      "Episode 810/1000\n",
      "Steps = 100/100 | Mean Reward = -2.824 | Mean Iteration time = 2.55 s | Total Episode Time = 255.0s\n",
      "Episode 811/1000\n",
      "Steps = 100/100 | Mean Reward = -4.664 | Mean Iteration time = 2.516 s | Total Episode Time = 251.5s\n",
      "Episode 812/1000\n",
      "Steps = 100/100 | Mean Reward = 2.064 | Mean Iteration time = 2.547 s | Total Episode Time = 254.6s\n",
      "Episode 813/1000\n",
      "Steps = 100/100 | Mean Reward = 0.54 | Mean Iteration time = 2.533 s | Total Episode Time = 253.2s\n",
      "Episode 814/1000\n",
      "Steps = 100/100 | Mean Reward = 1.039 | Mean Iteration time = 2.457 s | Total Episode Time = 245.8s\n",
      "Episode 815/1000\n",
      "Steps = 100/100 | Mean Reward = 0.002321 | Mean Iteration time = 2.549 s | Total Episode Time = 254.9s\n",
      "Episode 816/1000\n",
      "Steps = 100/100 | Mean Reward = -4.926 | Mean Iteration time = 2.496 s | Total Episode Time = 249.6s\n",
      "Episode 817/1000\n",
      "Steps = 100/100 | Mean Reward = -1.954 | Mean Iteration time = 2.502 s | Total Episode Time = 250.2s\n",
      "Episode 818/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6924 | Mean Iteration time = 2.598 s | Total Episode Time = 259.8s\n",
      "Episode 819/1000\n",
      "Steps = 100/100 | Mean Reward = -0.07983 | Mean Iteration time = 2.543 s | Total Episode Time = 254.4s\n",
      "Episode 820/1000\n",
      "Steps = 100/100 | Mean Reward = -3.473 | Mean Iteration time = 2.453 s | Total Episode Time = 245.2s\n",
      "Episode 821/1000\n",
      "Steps = 100/100 | Mean Reward = 1.343 | Mean Iteration time = 2.582 s | Total Episode Time = 258.2s\n",
      "Episode 822/1000\n",
      "Steps = 100/100 | Mean Reward = -4.133 | Mean Iteration time = 2.54 s | Total Episode Time = 253.9s\n",
      "Episode 823/1000\n",
      "Steps = 100/100 | Mean Reward = -1.937 | Mean Iteration time = 2.447 s | Total Episode Time = 244.8s\n",
      "Episode 824/1000\n",
      "Steps = 100/100 | Mean Reward = -2.97 | Mean Iteration time = 2.453 s | Total Episode Time = 245.4s\n",
      "Episode 825/1000\n",
      "Steps = 100/100 | Mean Reward = -2.613 | Mean Iteration time = 2.502 s | Total Episode Time = 250.1s\n",
      "Episode 826/1000\n",
      "Steps = 100/100 | Mean Reward = -6.164 | Mean Iteration time = 2.494 s | Total Episode Time = 249.5s\n",
      "Episode 827/1000\n",
      "Steps = 100/100 | Mean Reward = -1.581 | Mean Iteration time = 2.477 s | Total Episode Time = 247.8s\n",
      "Episode 828/1000\n",
      "Steps = 100/100 | Mean Reward = -4.973 | Mean Iteration time = 2.45 s | Total Episode Time = 244.9s\n",
      "Episode 829/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3188 | Mean Iteration time = 2.658 s | Total Episode Time = 265.8s\n",
      "Episode 830/1000\n",
      "Steps = 100/100 | Mean Reward = -4.504 | Mean Iteration time = 2.512 s | Total Episode Time = 251.2s\n",
      "Episode 831/1000\n",
      "Steps = 100/100 | Mean Reward = -2.838 | Mean Iteration time = 2.523 s | Total Episode Time = 252.2s\n",
      "Episode 832/1000\n",
      "Steps = 100/100 | Mean Reward = -2.19 | Mean Iteration time = 2.543 s | Total Episode Time = 254.4s\n",
      "Episode 833/1000\n",
      "Steps = 100/100 | Mean Reward = -3.725 | Mean Iteration time = 2.545 s | Total Episode Time = 254.5s\n",
      "Episode 834/1000\n",
      "Steps = 100/100 | Mean Reward = -1.049 | Mean Iteration time = 2.516 s | Total Episode Time = 251.5s\n",
      "Episode 835/1000\n",
      "Steps = 100/100 | Mean Reward = -3.645 | Mean Iteration time = 2.572 s | Total Episode Time = 257.2s\n",
      "Episode 836/1000\n",
      "Steps = 100/100 | Mean Reward = 0.354 | Mean Iteration time = 2.467 s | Total Episode Time = 246.8s\n",
      "Episode 837/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8223 | Mean Iteration time = 2.5 s | Total Episode Time = 250.0s\n",
      "Episode 838/1000\n",
      "Steps = 100/100 | Mean Reward = -5.29 | Mean Iteration time = 2.502 s | Total Episode Time = 250.2s\n",
      "Episode 839/1000\n",
      "Steps = 100/100 | Mean Reward = -4.266 | Mean Iteration time = 2.51 s | Total Episode Time = 251.0s\n",
      "Episode 840/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8706 | Mean Iteration time = 2.514 s | Total Episode Time = 251.4s\n",
      "Episode 841/1000\n",
      "Steps = 100/100 | Mean Reward = -1.385 | Mean Iteration time = 2.494 s | Total Episode Time = 249.4s\n",
      "Episode 842/1000\n",
      "Steps = 100/100 | Mean Reward = 2.023 | Mean Iteration time = 2.514 s | Total Episode Time = 251.4s\n",
      "Episode 843/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3743 | Mean Iteration time = 2.607 s | Total Episode Time = 260.8s\n",
      "Episode 844/1000\n",
      "Steps = 100/100 | Mean Reward = -5.566 | Mean Iteration time = 2.488 s | Total Episode Time = 248.9s\n",
      "Episode 845/1000\n",
      "Steps = 100/100 | Mean Reward = -3.912 | Mean Iteration time = 2.527 s | Total Episode Time = 252.8s\n",
      "Episode 846/1000\n",
      "Steps = 100/100 | Mean Reward = -1.545 | Mean Iteration time = 2.479 s | Total Episode Time = 247.9s\n",
      "Episode 847/1000\n",
      "Steps = 100/100 | Mean Reward = 0.12445 | Mean Iteration time = 2.615 s | Total Episode Time = 261.5s\n",
      "Episode 848/1000\n",
      "Steps = 100/100 | Mean Reward = -3.03 | Mean Iteration time = 2.475 s | Total Episode Time = 247.5s\n",
      "Episode 849/1000\n",
      "Steps = 100/100 | Mean Reward = -3.355 | Mean Iteration time = 2.506 s | Total Episode Time = 250.5s\n",
      "Episode 850/1000\n",
      "Steps = 100/100 | Mean Reward = -2.438 | Mean Iteration time = 2.51 s | Total Episode Time = 251.0s\n",
      "Episode 851/1000\n",
      "Steps = 100/100 | Mean Reward = 0.2158 | Mean Iteration time = 2.57 s | Total Episode Time = 257.0s\n",
      "Episode 852/1000\n",
      "Steps = 100/100 | Mean Reward = -2.148 | Mean Iteration time = 2.5 s | Total Episode Time = 250.0s\n",
      "Episode 853/1000\n",
      "Steps = 100/100 | Mean Reward = -3.633 | Mean Iteration time = 2.443 s | Total Episode Time = 244.4s\n",
      "Episode 854/1000\n",
      "Steps = 100/100 | Mean Reward = -2.688 | Mean Iteration time = 2.5 s | Total Episode Time = 250.0s\n",
      "Episode 855/1000\n",
      "Steps = 100/100 | Mean Reward = 1.746 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 856/1000\n",
      "Steps = 100/100 | Mean Reward = -1.85 | Mean Iteration time = 2.445 s | Total Episode Time = 244.5s\n",
      "Episode 857/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6904 | Mean Iteration time = 2.49 s | Total Episode Time = 249.0s\n",
      "Episode 858/1000\n",
      "Steps = 100/100 | Mean Reward = -3.225 | Mean Iteration time = 2.479 s | Total Episode Time = 247.9s\n",
      "Episode 859/1000\n",
      "Steps = 100/100 | Mean Reward = -4.688 | Mean Iteration time = 2.477 s | Total Episode Time = 247.6s\n",
      "Episode 860/1000\n",
      "Steps = 100/100 | Mean Reward = -3.428 | Mean Iteration time = 2.52 s | Total Episode Time = 251.9s\n",
      "Episode 861/1000\n",
      "Steps = 100/100 | Mean Reward = 0.8213 | Mean Iteration time = 2.545 s | Total Episode Time = 254.5s\n",
      "Episode 862/1000\n",
      "Steps = 100/100 | Mean Reward = -0.868 | Mean Iteration time = 2.52 s | Total Episode Time = 252.0s\n",
      "Episode 863/1000\n",
      "Steps = 100/100 | Mean Reward = -3.355 | Mean Iteration time = 2.445 s | Total Episode Time = 244.5s\n",
      "Episode 864/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2737 | Mean Iteration time = 2.516 s | Total Episode Time = 251.5s\n",
      "Episode 865/1000\n",
      "Steps = 100/100 | Mean Reward = -1.253 | Mean Iteration time = 2.512 s | Total Episode Time = 251.1s\n",
      "Episode 866/1000\n",
      "Steps = 100/100 | Mean Reward = 1.326 | Mean Iteration time = 2.453 s | Total Episode Time = 245.4s\n",
      "Episode 867/1000\n",
      "Steps = 100/100 | Mean Reward = -2.164 | Mean Iteration time = 2.504 s | Total Episode Time = 250.4s\n",
      "Episode 868/1000\n",
      "Steps = 100/100 | Mean Reward = -0.12335 | Mean Iteration time = 2.486 s | Total Episode Time = 248.6s\n",
      "Episode 869/1000\n",
      "Steps = 100/100 | Mean Reward = -2.059 | Mean Iteration time = 2.568 s | Total Episode Time = 256.8s\n",
      "Episode 870/1000\n",
      "Steps = 100/100 | Mean Reward = -2.373 | Mean Iteration time = 2.55 s | Total Episode Time = 255.1s\n",
      "Episode 871/1000\n",
      "Steps = 100/100 | Mean Reward = -3.098 | Mean Iteration time = 2.479 s | Total Episode Time = 247.9s\n",
      "Episode 872/1000\n",
      "Steps = 100/100 | Mean Reward = -1.442 | Mean Iteration time = 2.508 s | Total Episode Time = 250.9s\n",
      "Episode 873/1000\n",
      "Steps = 100/100 | Mean Reward = -0.373 | Mean Iteration time = 2.457 s | Total Episode Time = 245.8s\n",
      "Episode 874/1000\n",
      "Steps = 100/100 | Mean Reward = -3.81 | Mean Iteration time = 2.555 s | Total Episode Time = 255.5s\n",
      "Episode 875/1000\n",
      "Steps = 100/100 | Mean Reward = -2.773 | Mean Iteration time = 2.467 s | Total Episode Time = 246.6s\n",
      "Episode 876/1000\n",
      "Steps = 100/100 | Mean Reward = -0.02928 | Mean Iteration time = 2.506 s | Total Episode Time = 250.6s\n",
      "Episode 877/1000\n",
      "Steps = 100/100 | Mean Reward = -1.582 | Mean Iteration time = 2.537 s | Total Episode Time = 253.8s\n",
      "Episode 878/1000\n",
      "Steps = 100/100 | Mean Reward = -3.395 | Mean Iteration time = 2.557 s | Total Episode Time = 255.8s\n",
      "Episode 879/1000\n",
      "Steps = 100/100 | Mean Reward = -2.717 | Mean Iteration time = 2.494 s | Total Episode Time = 249.4s\n",
      "Episode 880/1000\n",
      "Steps = 100/100 | Mean Reward = -1.425 | Mean Iteration time = 2.506 s | Total Episode Time = 250.6s\n",
      "Episode 881/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3022 | Mean Iteration time = 2.508 s | Total Episode Time = 250.9s\n",
      "Episode 882/1000\n",
      "Steps = 100/100 | Mean Reward = -0.5884 | Mean Iteration time = 2.582 s | Total Episode Time = 258.2s\n",
      "Episode 883/1000\n",
      "Steps = 100/100 | Mean Reward = -1.746 | Mean Iteration time = 2.52 s | Total Episode Time = 252.0s\n",
      "Episode 884/1000\n",
      "Steps = 100/100 | Mean Reward = -2.275 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 885/1000\n",
      "Steps = 100/100 | Mean Reward = -2.088 | Mean Iteration time = 2.535 s | Total Episode Time = 253.5s\n",
      "Episode 886/1000\n",
      "Steps = 100/100 | Mean Reward = -1.248 | Mean Iteration time = 2.545 s | Total Episode Time = 254.5s\n",
      "Episode 887/1000\n",
      "Steps = 100/100 | Mean Reward = -1.072 | Mean Iteration time = 2.48 s | Total Episode Time = 248.1s\n",
      "Episode 888/1000\n",
      "Steps = 100/100 | Mean Reward = -1.796 | Mean Iteration time = 2.494 s | Total Episode Time = 249.5s\n",
      "Episode 889/1000\n",
      "Steps = 100/100 | Mean Reward = -0.0082 | Mean Iteration time = 2.521 s | Total Episode Time = 252.1s\n",
      "Episode 890/1000\n",
      "Steps = 100/100 | Mean Reward = -2.158 | Mean Iteration time = 2.447 s | Total Episode Time = 244.8s\n",
      "Episode 891/1000\n",
      "Steps = 100/100 | Mean Reward = 0.551 | Mean Iteration time = 2.443 s | Total Episode Time = 244.2s\n",
      "Episode 892/1000\n",
      "Steps = 100/100 | Mean Reward = -3.107 | Mean Iteration time = 2.475 s | Total Episode Time = 247.5s\n",
      "Episode 893/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4712 | Mean Iteration time = 2.494 s | Total Episode Time = 249.4s\n",
      "Episode 894/1000\n",
      "Steps = 100/100 | Mean Reward = -4.2 | Mean Iteration time = 2.506 s | Total Episode Time = 250.6s\n",
      "Episode 895/1000\n",
      "Steps = 100/100 | Mean Reward = -0.3694 | Mean Iteration time = 2.586 s | Total Episode Time = 258.5s\n",
      "Episode 896/1000\n",
      "Steps = 100/100 | Mean Reward = -0.9155 | Mean Iteration time = 2.52 s | Total Episode Time = 251.9s\n",
      "Episode 897/1000\n",
      "Steps = 100/100 | Mean Reward = -1.304 | Mean Iteration time = 2.504 s | Total Episode Time = 250.4s\n",
      "Episode 898/1000\n",
      "Steps = 100/100 | Mean Reward = -3.973 | Mean Iteration time = 2.557 s | Total Episode Time = 255.6s\n",
      "Episode 899/1000\n",
      "Steps = 100/100 | Mean Reward = -2.818 | Mean Iteration time = 2.705 s | Total Episode Time = 270.5s\n",
      "Episode 900/1000\n",
      "Steps = 100/100 | Mean Reward = -2.914 | Mean Iteration time = 2.94 s | Total Episode Time = 294.0s\n",
      "Episode 901/1000\n",
      "Steps = 100/100 | Mean Reward = -1.401 | Mean Iteration time = 2.756 s | Total Episode Time = 275.5s\n",
      "Episode 902/1000\n",
      "Steps = 100/100 | Mean Reward = -4.12 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 903/1000\n",
      "Steps = 100/100 | Mean Reward = 3.293 | Mean Iteration time = 2.725 s | Total Episode Time = 272.5s\n",
      "Episode 904/1000\n",
      "Steps = 100/100 | Mean Reward = -2.297 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 905/1000\n",
      "Steps = 100/100 | Mean Reward = -0.6094 | Mean Iteration time = 2.867 s | Total Episode Time = 286.8s\n",
      "Episode 906/1000\n",
      "Steps = 100/100 | Mean Reward = -1.798 | Mean Iteration time = 2.775 s | Total Episode Time = 277.5s\n",
      "Episode 907/1000\n",
      "Steps = 100/100 | Mean Reward = -8.77 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 908/1000\n",
      "Steps = 100/100 | Mean Reward = 0.893 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 909/1000\n",
      "Steps = 100/100 | Mean Reward = -7.336 | Mean Iteration time = 2.668 s | Total Episode Time = 266.8s\n",
      "Episode 910/1000\n",
      "Steps = 100/100 | Mean Reward = -2.023 | Mean Iteration time = 2.725 s | Total Episode Time = 272.5s\n",
      "Episode 911/1000\n",
      "Steps = 100/100 | Mean Reward = -3.465 | Mean Iteration time = 2.818 s | Total Episode Time = 281.8s\n",
      "Episode 912/1000\n",
      "Steps = 100/100 | Mean Reward = -4.383 | Mean Iteration time = 2.717 s | Total Episode Time = 271.8s\n",
      "Episode 913/1000\n",
      "Steps = 100/100 | Mean Reward = -0.632 | Mean Iteration time = 2.748 s | Total Episode Time = 274.8s\n",
      "Episode 914/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7485 | Mean Iteration time = 2.734 s | Total Episode Time = 273.5s\n",
      "Episode 915/1000\n",
      "Steps = 100/100 | Mean Reward = -1.146 | Mean Iteration time = 2.742 s | Total Episode Time = 274.2s\n",
      "Episode 916/1000\n",
      "Steps = 100/100 | Mean Reward = 1.482 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 917/1000\n",
      "Steps = 100/100 | Mean Reward = -4.773 | Mean Iteration time = 2.668 s | Total Episode Time = 266.8s\n",
      "Episode 918/1000\n",
      "Steps = 100/100 | Mean Reward = -6.934 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 919/1000\n",
      "Steps = 100/100 | Mean Reward = -3.518 | Mean Iteration time = 2.742 s | Total Episode Time = 274.2s\n",
      "Episode 920/1000\n",
      "Steps = 100/100 | Mean Reward = -4.473 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 921/1000\n",
      "Steps = 100/100 | Mean Reward = -3.777 | Mean Iteration time = 2.695 s | Total Episode Time = 269.5s\n",
      "Episode 922/1000\n",
      "Steps = 100/100 | Mean Reward = -3.812 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 923/1000\n",
      "Steps = 100/100 | Mean Reward = -2.807 | Mean Iteration time = 2.744 s | Total Episode Time = 274.5s\n",
      "Episode 924/1000\n",
      "Steps = 100/100 | Mean Reward = -4.17 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 925/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8306 | Mean Iteration time = 2.793 s | Total Episode Time = 279.2s\n",
      "Episode 926/1000\n",
      "Steps = 100/100 | Mean Reward = -3.2 | Mean Iteration time = 2.74 s | Total Episode Time = 274.0s\n",
      "Episode 927/1000\n",
      "Steps = 100/100 | Mean Reward = -7.08 | Mean Iteration time = 2.705 s | Total Episode Time = 270.5s\n",
      "Episode 928/1000\n",
      "Steps = 100/100 | Mean Reward = -2.373 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 929/1000\n",
      "Steps = 100/100 | Mean Reward = -1.727 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 930/1000\n",
      "Steps = 100/100 | Mean Reward = -5.12 | Mean Iteration time = 2.766 s | Total Episode Time = 276.5s\n",
      "Episode 931/1000\n",
      "Steps = 100/100 | Mean Reward = -0.313 | Mean Iteration time = 2.756 s | Total Episode Time = 275.5s\n",
      "Episode 932/1000\n",
      "Steps = 100/100 | Mean Reward = 0.08734 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 933/1000\n",
      "Steps = 100/100 | Mean Reward = -0.2367 | Mean Iteration time = 2.805 s | Total Episode Time = 280.5s\n",
      "Episode 934/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4038 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 935/1000\n",
      "Steps = 100/100 | Mean Reward = -2.967 | Mean Iteration time = 2.727 s | Total Episode Time = 272.8s\n",
      "Episode 936/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3057 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 937/1000\n",
      "Steps = 100/100 | Mean Reward = -3.117 | Mean Iteration time = 2.873 s | Total Episode Time = 287.2s\n",
      "Episode 938/1000\n",
      "Steps = 100/100 | Mean Reward = -5.773 | Mean Iteration time = 2.688 s | Total Episode Time = 268.8s\n",
      "Episode 939/1000\n",
      "Steps = 100/100 | Mean Reward = 0.311 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 940/1000\n",
      "Steps = 100/100 | Mean Reward = -4.137 | Mean Iteration time = 2.775 s | Total Episode Time = 277.5s\n",
      "Episode 941/1000\n",
      "Steps = 100/100 | Mean Reward = -3.715 | Mean Iteration time = 2.748 s | Total Episode Time = 274.8s\n",
      "Episode 942/1000\n",
      "Steps = 100/100 | Mean Reward = -0.301 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 943/1000\n",
      "Steps = 100/100 | Mean Reward = -3.285 | Mean Iteration time = 2.887 s | Total Episode Time = 288.8s\n",
      "Episode 944/1000\n",
      "Steps = 100/100 | Mean Reward = -1.468 | Mean Iteration time = 2.662 s | Total Episode Time = 266.2s\n",
      "Episode 945/1000\n",
      "Steps = 100/100 | Mean Reward = 0.566 | Mean Iteration time = 2.693 s | Total Episode Time = 269.2s\n",
      "Episode 946/1000\n",
      "Steps = 100/100 | Mean Reward = -1.63 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 947/1000\n",
      "Steps = 100/100 | Mean Reward = -1.172 | Mean Iteration time = 2.643 s | Total Episode Time = 264.2s\n",
      "Episode 948/1000\n",
      "Steps = 100/100 | Mean Reward = -0.628 | Mean Iteration time = 2.682 s | Total Episode Time = 268.2s\n",
      "Episode 949/1000\n",
      "Steps = 100/100 | Mean Reward = -0.7017 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 950/1000\n",
      "Steps = 100/100 | Mean Reward = -2.37 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 951/1000\n",
      "Steps = 100/100 | Mean Reward = -3.572 | Mean Iteration time = 2.627 s | Total Episode Time = 262.8s\n",
      "Episode 952/1000\n",
      "Steps = 100/100 | Mean Reward = -2.328 | Mean Iteration time = 2.72 s | Total Episode Time = 272.0s\n",
      "Episode 953/1000\n",
      "Steps = 100/100 | Mean Reward = -1.589 | Mean Iteration time = 2.652 s | Total Episode Time = 265.2s\n",
      "Episode 954/1000\n",
      "Steps = 100/100 | Mean Reward = -1.901 | Mean Iteration time = 2.787 s | Total Episode Time = 278.8s\n",
      "Episode 955/1000\n",
      "Steps = 100/100 | Mean Reward = 0.4321 | Mean Iteration time = 2.713 s | Total Episode Time = 271.2s\n",
      "Episode 956/1000\n",
      "Steps = 100/100 | Mean Reward = -0.06085 | Mean Iteration time = 2.75 s | Total Episode Time = 275.0s\n",
      "Episode 957/1000\n",
      "Steps = 100/100 | Mean Reward = -5.156 | Mean Iteration time = 2.852 s | Total Episode Time = 285.2s\n",
      "Episode 958/1000\n",
      "Steps = 100/100 | Mean Reward = -1.531 | Mean Iteration time = 2.69 s | Total Episode Time = 269.0s\n",
      "Episode 959/1000\n",
      "Steps = 100/100 | Mean Reward = 0.326 | Mean Iteration time = 2.74 s | Total Episode Time = 274.0s\n",
      "Episode 960/1000\n",
      "Steps = 100/100 | Mean Reward = -1.135 | Mean Iteration time = 2.645 s | Total Episode Time = 264.5s\n",
      "Episode 961/1000\n",
      "Steps = 100/100 | Mean Reward = -0.314 | Mean Iteration time = 2.707 s | Total Episode Time = 270.8s\n",
      "Episode 962/1000\n",
      "Steps = 100/100 | Mean Reward = 2.016 | Mean Iteration time = 2.783 s | Total Episode Time = 278.2s\n",
      "Episode 963/1000\n",
      "Steps = 100/100 | Mean Reward = -3.64 | Mean Iteration time = 2.703 s | Total Episode Time = 270.2s\n",
      "Episode 964/1000\n",
      "Steps = 100/100 | Mean Reward = -3.48 | Mean Iteration time = 2.775 s | Total Episode Time = 277.5s\n",
      "Episode 965/1000\n",
      "Steps = 100/100 | Mean Reward = 0.475 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 966/1000\n",
      "Steps = 100/100 | Mean Reward = -3.14 | Mean Iteration time = 2.748 s | Total Episode Time = 274.8s\n",
      "Episode 967/1000\n",
      "Steps = 100/100 | Mean Reward = -1.176 | Mean Iteration time = 2.768 s | Total Episode Time = 276.8s\n",
      "Episode 968/1000\n",
      "Steps = 100/100 | Mean Reward = -1.374 | Mean Iteration time = 2.855 s | Total Episode Time = 285.5s\n",
      "Episode 969/1000\n",
      "Steps = 100/100 | Mean Reward = -2.922 | Mean Iteration time = 2.773 s | Total Episode Time = 277.2s\n",
      "Episode 970/1000\n",
      "Steps = 100/100 | Mean Reward = -2.271 | Mean Iteration time = 2.75 s | Total Episode Time = 275.0s\n",
      "Episode 971/1000\n",
      "Steps = 100/100 | Mean Reward = -1.652 | Mean Iteration time = 2.676 s | Total Episode Time = 267.5s\n",
      "Episode 972/1000\n",
      "Steps = 100/100 | Mean Reward = -3.275 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 973/1000\n",
      "Steps = 100/100 | Mean Reward = -4.227 | Mean Iteration time = 2.715 s | Total Episode Time = 271.5s\n",
      "Episode 974/1000\n",
      "Steps = 100/100 | Mean Reward = 1.055 | Mean Iteration time = 2.842 s | Total Episode Time = 284.2s\n",
      "Episode 975/1000\n",
      "Steps = 100/100 | Mean Reward = -0.685 | Mean Iteration time = 3.055 s | Total Episode Time = 305.5s\n",
      "Episode 976/1000\n",
      "Steps = 100/100 | Mean Reward = -1.678 | Mean Iteration time = 2.732 s | Total Episode Time = 273.2s\n",
      "Episode 977/1000\n",
      "Steps = 100/100 | Mean Reward = -1.825 | Mean Iteration time = 2.758 s | Total Episode Time = 275.8s\n",
      "Episode 978/1000\n",
      "Steps = 100/100 | Mean Reward = -3.65 | Mean Iteration time = 2.7 s | Total Episode Time = 270.0s\n",
      "Episode 979/1000\n",
      "Steps = 100/100 | Mean Reward = -2.047 | Mean Iteration time = 2.732 s | Total Episode Time = 273.2s\n",
      "Episode 980/1000\n",
      "Steps = 100/100 | Mean Reward = -0.8296 | Mean Iteration time = 2.676 s | Total Episode Time = 267.5s\n",
      "Episode 981/1000\n",
      "Steps = 100/100 | Mean Reward = -0.9043 | Mean Iteration time = 2.65 s | Total Episode Time = 265.0s\n",
      "Episode 982/1000\n",
      "Steps = 100/100 | Mean Reward = -2.484 | Mean Iteration time = 2.73 s | Total Episode Time = 273.0s\n",
      "Episode 983/1000\n",
      "Steps = 100/100 | Mean Reward = -0.908 | Mean Iteration time = 2.637 s | Total Episode Time = 263.8s\n",
      "Episode 984/1000\n",
      "Steps = 100/100 | Mean Reward = -3.664 | Mean Iteration time = 2.635 s | Total Episode Time = 263.5s\n",
      "Episode 985/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4697 | Mean Iteration time = 2.703 s | Total Episode Time = 270.2s\n",
      "Episode 986/1000\n",
      "Steps = 100/100 | Mean Reward = 1.198 | Mean Iteration time = 2.812 s | Total Episode Time = 281.2s\n",
      "Episode 987/1000\n",
      "Steps = 100/100 | Mean Reward = 1.589 | Mean Iteration time = 2.867 s | Total Episode Time = 286.8s\n",
      "Episode 988/1000\n",
      "Steps = 100/100 | Mean Reward = -1.202 | Mean Iteration time = 2.697 s | Total Episode Time = 269.8s\n",
      "Episode 989/1000\n",
      "Steps = 100/100 | Mean Reward = -1.682 | Mean Iteration time = 2.756 s | Total Episode Time = 275.5s\n",
      "Episode 990/1000\n",
      "Steps = 100/100 | Mean Reward = 3.662 | Mean Iteration time = 2.71 s | Total Episode Time = 271.0s\n",
      "Episode 991/1000\n",
      "Steps = 100/100 | Mean Reward = 0.3252 | Mean Iteration time = 2.855 s | Total Episode Time = 285.5s\n",
      "Episode 992/1000\n",
      "Steps = 100/100 | Mean Reward = -4.633 | Mean Iteration time = 2.803 s | Total Episode Time = 280.2s\n",
      "Episode 993/1000\n",
      "Steps = 100/100 | Mean Reward = -0.695 | Mean Iteration time = 2.93 s | Total Episode Time = 293.0s\n",
      "Episode 994/1000\n",
      "Steps = 100/100 | Mean Reward = 0.382 | Mean Iteration time = 3.05 s | Total Episode Time = 305.0s\n",
      "Episode 995/1000\n",
      "Steps = 100/100 | Mean Reward = 2.213 | Mean Iteration time = 2.838 s | Total Episode Time = 283.8s\n",
      "Episode 996/1000\n",
      "Steps = 100/100 | Mean Reward = -0.1051 | Mean Iteration time = 2.795 s | Total Episode Time = 279.5s\n",
      "Episode 997/1000\n",
      "Steps = 100/100 | Mean Reward = -0.763 | Mean Iteration time = 2.672 s | Total Episode Time = 267.2s\n",
      "Episode 998/1000\n",
      "Steps = 100/100 | Mean Reward = -0.79 | Mean Iteration time = 2.787 s | Total Episode Time = 278.8s\n",
      "Episode 999/1000\n",
      "Steps = 100/100 | Mean Reward = -2.973 | Mean Iteration time = 2.64 s | Total Episode Time = 264.0s\n",
      "Episode 1000/1000\n",
      "Steps = 100/100 | Mean Reward = -0.4946 | Mean Iteration time = 2.686 s | Total Episode Time = 268.5s\n"
     ]
    }
   ],
   "source": [
    "                         agent.train(env_name = 5555,\n",
    "      num_episodes = 1000,\n",
    "      max_steps = 100,\n",
    "      update_steps = 100,\n",
    "      num_policy_updates_per_aux = 16,\n",
    "      seed = 64,\n",
    "      save_every = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f408e-583d-4bbf-8818-24f1c9818a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "712b1bb9f9b201a39d484bf33b5adf39a3ffc64a74a1ee9d3eda9d3b9b673373"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
